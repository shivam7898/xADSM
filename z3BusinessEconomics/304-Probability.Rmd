# Probability {#c04}

```{r 'C04', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- This chapter covers Probability, Factorial, Combinations, Permutations, Bayes Theorem.
  - [Probability Basics](#assign-probability-c04 "c04")
  - "ForLater" - Exercises

## Probability

```{definition 'Probability'}
\textcolor{pink}{Probability} is a numerical measure of the likelihood that an event will occur. Probability values are always assigned on a scale from 0 to 1. A probability near zero indicates an event is unlikely to occur; a probability near 1 indicates an event is almost certain to occur.
```

```{definition 'Random-Experiment'}
A \textcolor{pink}{random experiment} is a process that generates well-defined experimental outcomes. On any single repetition or trial, the outcome that occurs is determined completely by chance. 
```

```{definition 'Sample-Space'}
The \textcolor{pink}{sample space} for a random experiment is the set of all experimental outcomes.
```

- Random experiment of tossing a coin has a Sample Space $S = \{\text{Head}, \text{Tail}\}$
- Random experiment of rolling a die has a Sample Space $S = \{1, 2, 3, 4, 5, 6\}$
- Random experiment of tossing Two coins has a Sample Space $S = \{\text{HH}, \text{HT}, \text{TH}, \text{TT}\}$

## Counting Rule 

```{definition 'Counting-Rule'}
\textcolor{pink}{Counting Rule for Multiple-Step Experiments:} If an experiment can be described as a sequence of ${k}$ steps with ${n_1}$ possible outcomes on the first step, ${n_2}$ possible outcomes on the second step, and so on, then the total number of experimental outcomes is given by $\{(n_1)(n_2) \cdots (n_k) \}$
```

```{definition 'Tree-Diagram'}
A \textcolor{pink}{tree diagram} is a graphical representation that helps in visualizing a multiple-step experiment. 
```

## Factorial 

```{definition 'Factorial'}
The \textcolor{pink}{factorial} of a non-negative integer ${n}$, denoted by $n!$, is the product of all positive integers less than or equal to n. The value of 0! is 1 i.e. \textcolor{pink}{$0!=1$}
```

\begin{equation} 
  \begin{align} 
    n! &= \prod _{i=1}^n i = n \cdot (n-1) \\
       &= n \cdot(n-1)\cdot(n-2)\cdot(n-3)\cdot\cdots \cdot 3 \cdot 2 \cdot 1 
  \end{align}
  (\#eq:factorial)
\end{equation} 

## Combinations

```{definition 'Combinations'}
\textcolor{pink}{Combination} allows one to count the number of experimental outcomes when the experiment involves selecting ${k}$ objects from a set of ${N}$ objects. The number of \textcolor{pink}{combinations} of ${N}$ objects taken ${k}$ at a time is equal to the \textcolor{pink}{binomial coefficient $C_k^N$}
```

\begin{equation} 
    C_k^N = \binom{N}{k} = \frac{N!}{k!(N-k)!}
  (\#eq:binom)
\end{equation} 

## Permutations

```{definition 'Permutations'}
\textcolor{pink}{Permutation} allows one to compute the number of experimental outcomes when ${k}$ objects are to be selected from a set of ${N}$ objects where the order of selection is important. The same ${k}$ objects selected in a different order are considered a different experimental outcome. The number of \textcolor{pink}{permutations} of ${N}$ objects taken ${k}$ at a time is given by \textcolor{pink}{$P_k^N$}
```

\begin{equation} 
    P_k^N = k! \binom{N}{k} = \frac{N!}{(N-k)!}
  (\#eq:permutation)
\end{equation} 

- \textcolor{pink}{The number of permutations of ${k}$ distinct objects is $k!$}
  - An experiment results in more permutations than combinations for the same number of objects because every selection of ${k}$ objects can be ordered in $k!$ different ways.

## Assigning Probabilities {#assign-probability-c04}

- Basic Requirements (Similar to the [Discrete Probability](#discrete-prob-be05 "be05") & [Continuos Probability](#continuous-prob-be06 "be06"))
  1. The probability assigned to each experimental outcome must be between 0 and 1, inclusively. If we let ${E_i}$ denote the $i^{th}$ experimental outcome and $P(E_i)$ its probability, then \textcolor{pink}{$P(E_i) \in [0, 1]$}
  1. The sum of the probabilities for all the experimental outcomes must equal 1. Thus for ${k}$ experimental outcomes \textcolor{pink}{$\sum _{i=1}^k P(E_i) =1$}

```{definition 'Event'}
An \textcolor{pink}{event} is a collection of sample points. The probability of any event is equal to the sum of the probabilities of the sample points in the event. The sample space, ${s}$, is an event. Because it contains all the experimental outcomes, it has a probability of 1; that is, \textcolor{pink}{$P(S) = 1$}
```

```{definition 'Complement'}
Given an event ${A}$, the \textcolor{pink}{complement of A ($A^c$)} is defined to be the event consisting of all sample points that are not in A. Thus, \textcolor{pink}{$P(A) + P(A^{c}) =1$}
```

```{definition 'Union'}
Given two events A and B, the \textcolor{pink}{union of A and B} is the event containing all sample points belonging to A or B or both. The union is denoted by \textcolor{pink}{$A \cup B$}
```

```{definition 'Intersection'}
Given two events A and B, the \textcolor{pink}{intersection of A and B} is the event containing the sample points belonging to both A and B. The intersection is denoted by \textcolor{pink}{$A \cap B$}
```

- Refer to the \textcolor{pink}{Addition Law} in the equation \@ref(eq:addition)

\begin{equation} 
    P(A \cup B) = P(A) + P(B) - P(A \cap B)
  (\#eq:addition)
\end{equation} 

```{definition 'Mutually-Exclusive'}
Two events are said to be \textcolor{pink}{mutually exclusive} if the events have no sample points in common. Thus, \textcolor{pink}{$A \cap B = 0$}
```

## Exercises

- How many ways can three items be selected from a group of six items
  - Solution: \textcolor{black}{$C_{3}^{6} = 6!/3!3! = 120$}
- In a experiment of tossing a coin three times, how many experimental outcomes can be
  - Solution: \textcolor{black}{$2^{3} = 8$}
- Simple random sampling uses a sample of size k from a population of size N to obtain data that can be used to make inferences about the characteristics of a population. Suppose that, from a population of 50 bank accounts, we want to take a random sample of four accounts in order to learn about the population. How many different random samples of four accounts are possible
  - Solution: \textcolor{black}{$C_{4}^{50} = 50!/4!46!$}
- To play Powerball, a participant must select five numbers from the digits 1 through 59, and then select a Powerball number from the digits 1 through 35. To determine the winning numbers for each game, lottery officials draw 5 white balls out a drum of 59 white balls numbered 1 through 59 and 1 red ball out of a 
drum of 35 red balls numbered 1 through 35. To win the Powerball jackpot, numbers on the lottery must match the numbers on the 5 white balls in any order and must also match the number on the red Powerball. How many Powerball lottery outcomes are possible
  - Solution: \textcolor{black}{$C_{5}^{59} \times C_{1}^{35}$}
- An experiment has four equally likely outcomes: E1, E2, E3, and E4
  - What is the probability that E2 occurs
    - Solution: \textcolor{black}{${1/4}$}
  - What is the probability that any two of the outcomes occur (e.g., E1 or E3)
    - Solution: \textcolor{black}{$2/4 = 1/2$}  
  - What is the probability that any three of the outcomes occur (e.g., E1 or E2 or E4)
    - Solution: \textcolor{black}{${3/4}$}  
- Consider the experiment of selecting a playing card from a deck of 52 playing cards. Each card corresponds to a sample point with a 1/52 probability.
  - Probability of the event that an ace is selected
    - Solution: \textcolor{black}{$4/52 = 1/13$}
  - Probability of the event that a club is selected
    - Solution: \textcolor{black}{$13/52 = 1/4$}
  - Probability of the event that  a face card (jack, queen, or king) is selected
    - Solution: \textcolor{black}{$4\times3/52$}
- Consider the experiment of rolling a pair of dice. Suppose that we are interested in the sum of the face values showing on the dice.
  - How many sample points are possible
    - Solution: \textcolor{black}{$6 \times 6 = 36$}
  - What is the probability of obtaining a value of 7
    - Solution: \textcolor{black}{$E_{7} = \{(1,6), (6,1), (2,5), (5,2), (3,4), (4,3)\} \Rightarrow P(E_{7}) = 6/36 = 1/6 $}
  - What is the probability of obtaining a value of 9 or greater
    - Solution: \textcolor{black}{$P(E_{\geq9}) = P(E_{9}, E_{10}, E_{11}, E_{12}) = \frac{4 + 3 + 2 + 1}{36} = \frac{5}{18}$}
  - Because each roll has six possible even values (2, 4, 6, 8, 10, and 12) and only five possible odd values (3, 5, 7, 9, and 11), the dice should show even values more often than odd values. Do you agree with this statement
    - Solution: \textcolor{black}{$\text{NO: } P(E_{\text{odd}}) = P(E_{\text{even}}) = 1/2 \iff E_{\text{odd}} = E_{\text{even}} = 18$}
- A survey of magazine subscribers showed that 45.8% rented a car during the past 12 months for business reasons, 54% rented a car during the past 12 months for personal reasons, and 30% rented a car during the past 12 months for both business and personal reasons.
  - Let B denote Business, P denote Personal
  - What is the probability that a subscriber rented a car during the past 12 months for business or personal reasons
    - Solution: \textcolor{black}{$P(B \cup P) = P(B) + P(P) - P(B \cap P) = 0.458 + 0.540 - 0.3 = 0.698$} 
  - What is the probability that a subscriber did not rent a car during the past 12 months for either business or personal reasons
  - Solution: \textcolor{black}{$P(B \cup P)^{c} = 1 - 0.698 = 0.302$} 

## Conditional Probability

```{definition 'Conditional-Probability'}
\textcolor{pink}{Conditional probability} is the probability of an event given that another event already 
occurred. The conditional probability of 'A given B' is \textcolor{pink}{$P(A|B) = \frac{P(A \cup B)}{P(B)}$}
```

```{r 'C04-Police', include=FALSE}
# #Police
xxPolice <- tibble(Promo_Gender = c('Promoted', 'NotPromoted'), Men = c(288, 672), Women = c(36, 204))
```

```{r 'C04T01', echo=FALSE}
aa <- xxPolice
bb <- aa %>% 
  bind_rows(aa %>% summarise(across(where(is.numeric), sum))) %>%
  mutate(across(1, ~replace(., . %in% NA, "Total"))) %>%
  mutate(SUM = rowSums(across(where(is.numeric)))) 
# #Probabilities
ii <- bb %>% mutate(across(where(is.numeric), ~./1200))
#
#displ_names <- c("") 
#stopifnot(identical(ncol(bb), length(displ_names)))
#
kk_bb <- kbl(bb,
  caption = "(C04T01) Police: Promotion and Gender",
  #col.names = displ_names,
  escape = FALSE, align = "c", booktabs = TRUE
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                html_font = "Consolas",	font_size = 12,
                full_width = FALSE,
                position = "float_left",
                fixed_thead = TRUE
  ) %>%
# #Header Row Dark & Bold: RGB (48, 48, 48) =HEX (#303030)
	row_spec(0, color = "white", background = "#303030", bold = TRUE,
	         extra_css = "border-bottom: 1px solid; border-top: 1px solid"
	)
#
#displ_names <- c("") 
#stopifnot(identical(ncol(bb), length(displ_names)))
#
kk_ii <- kbl(ii,
  caption = "(C04T01A) Joint and Marginal Probabilities",
  #col.names = displ_names,
  escape = FALSE, align = "c", booktabs = TRUE
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                html_font = "Consolas",	font_size = 12,
                full_width = FALSE,
                position = "float_left",
                fixed_thead = TRUE
  ) %>%
# #Header Row Dark & Bold: RGB (48, 48, 48) =HEX (#303030)
	row_spec(0, color = "white", background = "#303030", bold = TRUE,
	         extra_css = "border-bottom: 1px solid; border-top: 1px solid"
	)

# #Multiple Kable Tables
knitr::kables(list(kk_bb, kk_ii))
```

- Refer to the Police Promotion Table \@ref(tab:C04T01) 
  - Let, M (Man), W (Woman), A (Promoted), $A^{c}$ (Not Promoted)
  - Probability that a randomly selected officer ...
    - is man and is promoted: $P(A \cap M) = 288/1200 = 0.24$
    - is woman and is promoted: $P(A \cap W) = 36/1200 = 0.03$
    - is man and is not promoted: $P(A^{c} \cap M) = 672/1200 = 0.56$
    - is woman and is not promoted: $P(A^{c} \cap W) = 204/1200 = 0.17$
    - NOTE: Each of these are \textcolor{pink}{Joint Probabilities} because these provide intersection of two events.
  - \textcolor{pink}{Marginal probabilities} are the values in the margins of the joint probability table and indicate the probabilities of each event separately. 
    - $P(M) = 0.80, P(W) = 0.20, P(A) = 0.27, P(A^{c}) = 0.73$
    - Ex: the marginal probability of being promoted is $P(A) = P(A \cap M) + P(A \cap W)$
  - Conditional Probability Analysis
    - "the probability that an officer is promoted given that the officer is a man" $P(A|M)$
      - $P(A|M) = 288/960 = 0.30$
      - OR $P(A|M) = P(A \cap M) / P(M) = 0.24/0.80 = 0.30$
      - "Given that an officer is a man, that officer had a 30% chance of receiving a promotion"
    - "the probability that an officer is promoted given that the officer is a woman" $P(A|W)$
      - $P(A|W) = P(A \cap W) / P(W) = 0.03/0.20 = 0.15$
      - "Given that an officer is a woman, that officer had a 15% chance of receiving a promotion"
    - Conclusion
      - The probability of a promotion given that the officer is a man is .30, twice the .15 probability of a promotion given that the officer is a woman. 
      - Although the use of conditional probability does not in itself prove that discrimination exists in this case, the conditional probability values do support this argument.

```{definition 'Events-Independent'}
Two events A and B are independent if \textcolor{pink}{$P(A|B) = P(A) \quad \text{OR} \quad P(B|A) = P(B) \Rightarrow P(A \cap B) = P(A) \cdot P(B)$}
```

- Refer to the \textcolor{pink}{Multiplication Law} in the equation \@ref(eq:multiplication)
  - Example: 84% of the households in a neighborhood subscribe to the daily edition of a newspaper; that is, $P(D) =0.84$. In addition, it is known that the probability that a household that already holds a daily subscription also subscribes to the Sunday edition is .75; that is, $P(S|D) =0.75$ 
    - What is the probability that a household subscribes to both the Sunday and daily editions of the 
newspaper
      - $P(S \cap D) = P(D) \cdot P(S|D) = 0.84 \times 0.75 = 0.63$
      - "63% of the households subscribe to both the Sunday and daily editions"

\begin{equation} 
  \begin{align} 
    P(A \cap B) &= P(B) \cdot P(A | B) \\
       &= P(A) \cdot P(B | A) 
  \end{align}
  (\#eq:multiplication)
\end{equation} 

- Mutually Exclusive vs. Independent Events
  - Two events with nonzero probabilities cannot be both mutually exclusive and independent. 
  - If one mutually exclusive event is known to occur, the other cannot occur; thus, the probability of the other event occurring is reduced to zero. They are therefore dependent.

## Bayes Theorem

Often, we begin the analysis with initial or \textcolor{pink}{prior probability} estimates for specific events of interest. Then, from sources such as a sample, a special report, or a product test, we obtain additional information about the events. Given this new information, we update the prior probability 
values by calculating revised probabilities, referred to as \textcolor{pink}{posterior probabilities}. Bayes theorem provides a means for making these probability calculations. 

- Refer to the equation \@ref(eq:bayes)
  - \textcolor{pink}{Bayes theorem} is applicable when the events for which we want to compute posterior 
probabilities are mutually exclusive and their union is the entire sample space.
    - An event, $P(A)$, and its complement, $P(A^{c})$, are mutually exclusive, and their union is the entire sample space. Thus, Bayes theorem is always applicable for computing posterior probabilities of an event and its complement.
  - Example: A firm has two suppliers, currently 65% parts are supplied by one and remaining by other; that is, $P(A_{1}) = 0.65, P(A_{2}) = 0.35$. Quality of products supplied is 98% Good for supplier one and 95% Good for supplier 2.
    - $P(G|A_{1}) = 0.98, P(B|A_{1}) = 0.02$
    - $P(G|A_{2}) = 0.95, P(B|A_{2}) = 0.05$
    - Given that we received a Bad Part, what is the probability that it came from supplier 2
      - $P(A_{2}|B) = \frac{P(A_{2})P(B|A_{2})}{P(A_{1}) P(B|A_{1})+ P(A_{2}) P(B|A_{2})} = \frac{0.35 \times 0.05}{0.65 \times 0.02 + 0.35 \times 0.05} = 0.5738 \approx 57\%$
      - Similarly, $P(A_{1}|B) = 0.4262 \approx 43\%$
    - NOTE: While the Probability of a random part being from supplier 1 is $P(A_{1}) = 0.65$, it is reduced to $P(A_{1}|B) = 0.4262 \approx 43\%$ as we have received new information that the part is Bad.

\begin{equation} 
  \begin{align} 
    P(A_{1}|B) &= \frac{P(A_{1})P(B|A_{1})}{P(A_{1}) P(B|A_{1})+ P(A_{2}) P(B|A_{2})} \\
    P(A_{2}|B) &= \frac{P(A_{2})P(B|A_{2})}{P(A_{1}) P(B|A_{1})+ P(A_{2}) P(B|A_{2})}
  \end{align}
  (\#eq:bayes)
\end{equation} 

## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'C04-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ii, jj, kk, kk_bb, kk_ii, xxPolice)
```

```{r 'C04-Validation', include=FALSE, cache=FALSE}
# #Summarised Packages and Objects
f_()
#
difftime(Sys.time(), k_start)
```

****
