# Statistics (B13, Oct-03) {#b13}

```{r 'B13', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- "Introduction to Statistics"


- Links (Ref)
  - 


```{r 'B13-Flights', include=FALSE}
# #Load Data: Flights
xxflights <- f_getRDS(xxflights)
bb <- xxflights
```

## Definitions

```{r 'B13P01', echo=FALSE, ref.label=c('C09P01'), fig.cap="Type-I $(\\alpha)$ and Type-II $(\\beta)$ Errors"}
#knitr::include_graphics(paste0(.z$PX, "C09P01_Hypothesis_Errors.jpg")) #iiii
```

Refer [Type I and Type II Errors (B12)](#errors-ab-b12, "b12") & [Type I and Type II Errors](#errors-ab-c09, "c09")

```{r 'B13D01', comment="", echo=FALSE, results='asis'}
f_getDef("Error-Type-I")
```

```{r 'B13D02', comment="", echo=FALSE, results='asis'}
f_getDef("Error-Type-II") 
```

```{r 'B13D03', comment="", echo=FALSE, results='asis'}
f_getDef("Level-of-Significance")
```

```{r 'B13D04', comment="", echo=FALSE, results='asis'}
f_getDef("Confidence-Coefficient") 
```

```{r 'B13D05', comment="", echo=FALSE, results='asis'}
f_getDef("Power")
```

```{r 'B13D06', comment="", echo=FALSE, results='asis'}
f_getDef("Significance-Tests")
```

```{r 'B13D07', comment="", echo=FALSE, results='asis'}
f_getDef("Approach-p-value-Steps") 
```

```{r 'B13D08', comment="", echo=FALSE, results='asis'}
f_getDef("Standard-Error")
```


## Approaches {.tabset .tabset-fade}

Population Size = 100, ${\alpha} = 0.05$

Hypothesis: $\text{\{Right Tail or Upper Tail\} } {H_0} : {\mu} \leq 22 \iff {H_a}: {\mu} > 22$

Sample: n=4, dof = 3, ${\overline{x}} = 23$

Sample: n=10, dof = 9, ${\overline{x}} = 23$


We know if we take another sample, we will have a different sample mean. So, we need to confirm whether the above calculated sample mean ${\overline{x}} = 23$ represent the population mean ${\mu}$ i.e. Can we reject or fail to reject ${H_0}$ based on this sample!

3 Approaches for Hypothesis Testing - 

1.  Test Statistic Approach
    - Fictitious values: Standard Error (SE) = 0.22, so $t = \frac{23 - 22}{0.22} = 4.545$
    - For (DOF = 3): $P_{(t)} = {\alpha} = 0.05$, at ${}^{3}t_{\alpha} = 2.353$
    - For (DOF = 9): $P_{(t)} = {\alpha} = 0.05$, at ${}^{9}t_{\alpha} = 1.833$
    - For both the cases, ${t}$ is greater than ${}^{dof}t_{\alpha}$
    - Hence null is rejected, the 'test is statistically significant'
1.  p-value approach 
    - Fictitious values: Standard Error (SE) = 0.22, so $t = \frac{23 - 22}{0.22} = 4.545$
    - Get ${}^3\!P_{(t = 4.545)} = 0.00997$
    - Get ${}^9\!P_{(t = 4.545)} = 0.000697$
    - For both the cases, $P_{(t)}$ is lower than ${\alpha}$
    - Hence null is rejected, the 'test is statistically significant'

1.  Confidence Interval Approach


If the population standard error (SE) is known, apply z-test. If it is unknown, apply t-test. t-test will converge to z-test with increasing sample size.

2-T Rule of Thumb - Skipped "09:55"


```{r 'B-GetPz', include=TRUE}
# #Get P(z)
z01 <- round(pnorm(3.44), digits = 6)
z02 <- 1 - round(pnorm(3.44), digits = 6)
z03 <- round(pnorm(3.44, lower.tail = FALSE), digits = 6)
z04 <- format(pnorm(4.55, lower.tail = FALSE), digits = 3, scientific = FALSE)
z05 <- format(pnorm(1.22, lower.tail = FALSE), digits = 5)
z06 <- format(pnorm(1.99, lower.tail = FALSE), digits = 5)
z07 <- format(pnorm(1.99, lower.tail = TRUE), digits = 5)
```

### Examples {.unlisted .unnumbered}

Example: 

1. \textcolor{pink}{Question:} If we get a z-value of 3.44 (Right Tail), What is the Probability $P_{(z)}$
    - For z = 3.44 & Left Tail, p-value = `r z01` (by \textcolor{pink}{`pnorm(z)`})
    - For z = 3.44 & Right Tail, p-value = `r z02` (by \textcolor{pink}{`1 - pnorm(z)`})
    - For z = 3.44 & Right Tail, p-value = `r z03` (by \textcolor{pink}{`pnorm(z, lower.tail = FALSE)`})
1. \textcolor{pink}{Question:} If we get a z-value of 4.55 (Right Tail), What is the Probability $P_{(z)}$
    - For z = 4.55 & Right Tail, p-value = `r z04` 
1. \textcolor{pink}{Question:} If we get a z-value of 1.22 (Right Tail), would we reject the null at ${\alpha} = 0.05$
    - For z = 1.22 & Right Tail, p-value = `r z05` 
    - Because $P_{(z)}$ is greater than the ${\alpha}$, we fail to reject the null, the 'test is statistically NOT significant'
1.  \textcolor{pink}{Question:} If we get a z-value of 1.99 (Right Tail), would we reject the null at ${\alpha} = 0.05$
    - For z = 1.99 & Right Tail, p-value = `r z06` ( = 1 - `r z07`)
    - Because $P_{(z)}$ is lower than the ${\alpha}$, null is rejected, the 'test is statistically significant'    

### Code {.unlisted .unnumbered}

```{r 'B-GetPz-A', ref.label=c('B-GetPz'), eval=FALSE}
#
```

### Flowchart

- Tests |
  - Test of Means |
    - One Sample |
      - z-test (Population Standard Deviation ${\sigma}$, is known)
      - t-test (Population Standard Deviation ${\sigma}$, is unknown)
    - Two Sample | 
      - Independent Sample | [Mean - Two Sample - Independent](#mean-2s-sd "c10")
      - Dependent Sample (or Repeated) | [Mean - Two Sample - Paired](#mean-paired-c10 "c10")
    - More than Two Samples
-

## Two Sample t-Test

```{r 'B13D11', comment="", echo=FALSE, results='asis'}
f_getDef("Hypo-2Sample-Lower")
```

```{r 'B13D12', comment="", echo=FALSE, results='asis'}
f_getDef("Hypo-2Sample-Upper")
```

```{r 'B13D13', comment="", echo=FALSE, results='asis'}
f_getDef("Hypo-2Sample-Two") #dddd
```

Example: 

```{r 'B13D09', comment="", echo=FALSE, results='asis'}
f_getDef("Independent-Sample-Design-Example")
```

```{r 'B13D10', comment="", echo=FALSE, results='asis'}
f_getDef("Matched-Sample-Design-Example")
```

Test Statistic for Independent Sample t-Test Statistic is given by \@ref(eq:t-2s-nsd) as shown below

\begin{equation}
  t = \frac{({\overline{x}}_1 - {\overline{x}}_2) - {D}_0}{{\sigma}_{({\overline{x}}_1 - {\overline{x}}_2)}} = \frac{({\overline{x}}_1 - {\overline{x}}_2) - {D}_0}{\sqrt{\frac{{s}_1^2}{{n}_1} + \frac{{s}_2^2}{{n}_2}}}
\end{equation}

The t-test is any statistical hypothesis test in which the test statistic follows a Student's t-distribution under the null hypothesis.

A t-test is the most commonly applied when the test statistic would follow a normal distribution if the value of a scaling term in the test statistic were known. 


Example: If we want to evaluate effect of a Training Program.

We can take two samples of 50 people each. First Set "Untrained" would be from the set of people who did not receive training. Second Set "Trained" would be from the set of people who have undergone the training. Comparison of these two sample mean performances would be done by "independent sample" t-test.

Or

We can take a sample of 50 "Untrained" people. Get their mean performance. Provide the training of these 50 people. Then again get their mean performance. Now, we have "paired" samples of performances of same people. One set has their performance before the training and another is after the training. Comparison of these two sample mean performances would be done by "paired sample" t-test.

Paired samples t-tests typically consist of a sample of matched pairs of similar units, or one group of units that has been tested twice (a "repeated measures" t-test). 

The matched sample design is generally preferred to the independent sample design because \textcolor{pink}{the matched-sample procedure often improves the precision of the estimate.}

- \textcolor{pink}{Question:} How do you conclude that the training was effective. Or even that the training didnot make the situation worse somehow. Assume 25 people performed better and 25 people performed worse (somehow!)
  - (Prof) In this situation we cannot claim that the training is effective.
    - We start with the null hypothesis that the two sample means are same (Two Tail Test). If we are able to reject this. Then we can perform Upper or Lower Tail Test and again try to find a significant result.
  - If we cannot reject the null hypothesis, then we conclude that "we cannot claim that the training is effective".


- Example: If we want to comment on performance of new employees compared to ideal value of 95. Take a sample of 20 people and get their perfomance. 
  - We would need to perform One Sample t-test
- Example: If we want to comment on performance of Engineers and Non-engineers
  - Two Sample Independent t-test
- Example: We want to check whether we have recruited more number of females compared to males. 
  - Two Sample Proportion Test
- Example: If we want to comment on their induction training program by conducting a test before and after the program
  - Two Sample Paired t-test

## More than Two Samples




## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B13-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ee, hh, ii, jj, kk, ll, mm, nn, oo, rr, vv, xx, yy, zz, z01, z02, z03, z04, z05, z06, z07)
```

```{r 'B13-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
