# Linear Regression (B28, Jan-16) {#b28}

```{r 'B28', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```


## Overview

- "Machine learning using linear regression"
- Refer [Bias-Variance Trade-off](#bias-var-c37 "c37")

```{r 'B28D01', comment="", echo=FALSE, results='asis'}
f_getDef("Bias-Variance-Trade-off")
```

```{r 'B28D02', comment="", echo=FALSE, results='asis'}
f_getDef("Coefficient-of-Determination") 
```

```{r 'B28D03', comment="", echo=FALSE, results='asis'}
f_getDef("Overfitting")
```

```{r 'B28D04', comment="", echo=FALSE, results='asis'}
f_getDef("Underfitting")
```

```{r 'B28P01', echo=FALSE, ref.label=c('C37P01'), fig.cap="(C37P01) Bias-Variance Trade-off"}
# #Ref another file chunk
```

```{r 'B28D05', comment="", echo=FALSE, results='asis'}
f_getDef("Residuals")
```

```{r 'B28D06', comment="", echo=FALSE, results='asis'}
f_getDef("RSq-Adj")
```

```{r 'B28D07', comment="", echo=FALSE, results='asis'}
f_getDef("Multicollinearity")
```

```{r 'B28D08', comment="", echo=FALSE, results='asis'}
f_getDef("Principle-of-Parsimony") #iiii
```

## WIP


```{r 'B28-1', include=FALSE, eval=FALSE}
data("BostonHousing")
bb <- BostonHousing
#
```


```{r 'B28-2', include=FALSE, eval=FALSE}
pairs.panels(bb[c(-4,-14)], cex = 2)
```


```{r 'B28-3', include=FALSE, eval=FALSE}
set.seed (1234)
index <- sample(2, nrow(bb), replace = TRUE, prob = c(.70,.30))
train <- bb[index ==1, ]
test <- bb[index ==2, ]
```


```{r 'B28-4', include=FALSE, eval=FALSE}
#custom control parameters

custom <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
```


```{r 'B28-5', include=FALSE, eval=FALSE}
# RUNNING A LINEAR REGRESSION MODEL
set.seed (1234)
linear <- train(medv~., train, method = "lm", trControl = custom)
linear$results
#linear
#summary(linear)
linear1 <- lm(medv~., data = train)# no cross validation 
#summary(linear1)
```


```{r 'B28-6', include=FALSE, eval=FALSE}
# RIDGE REGRESSION
set.seed (1234)

ridge <- train (medv~., train, method = "glmnet", 
                tuneGrid = expand.grid(alpha = 0, lambda = seq(0.0001, 1, length = 5)), 
                trControl = custom)
#ridge
#plot(ridge)
#plot (ridge$finalModel, xvar = "lambda", label = TRUE)
#plot(varImp(ridge, scale = TRUE))# draw variable importance plot
```


```{r 'B28-7', include=FALSE, eval=FALSE}
#LASSO REGRESSION(LASSO" stands for Least Absolute Shrinkage and Selection Operator)
set.seed(1234)

lasso <- train (medv~., train, method = "glmnet",
                tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 5)), 
                trControl = custom)
#lasso
#plot(lasso)
#plot(varImp(lasso, scale = TRUE))
```


```{r 'B28-8', include=FALSE, eval=FALSE}
#ELASTIC NET REGRESSION
set.seed (1234)

elastic <- train (medv~., train, method = "glmnet", 
                  tuneGrid = expand.grid(alpha = seq(0,1, length = 10), 
                                         lambda = seq(0.0001, 1, length = 5)), trControl = custom)
#plot(elastic)
#elastic <- train (medv~., train, method = "glmnet", 
#                  tuneGrid = expand.grid(alpha = seq(0,1, length = 10), 
#                                         lambda = seq(0.0001, 0.2, length = 5)),
#                  trControl = custom)

#elastic
#varImp(elastic)
#plot(varImp(elastic))
```


```{r 'B28-9', include=FALSE, eval=FALSE}
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
#summary(compare)
```


```{r 'B28-10', include=FALSE, eval=FALSE}
## BEST MODEL
ridge$bestTune
lasso$bestTune
elastic$bestTune
```


```{r 'B28-11', include=FALSE, eval=FALSE}
## to examine the coefficients
best <-elastic$finalModel
coef(best, s = elastic$bestTune$lambda)
```


```{r 'B28-12', include=FALSE, eval=FALSE}
#saveRDS(elastic, "finalmodel.rds")
#final <-readRDS("finalmodel.rds")
#print(final)
final <- elastic
```


```{r 'B28-13', include=FALSE, eval=FALSE}
##### PREDICTION
P1<- predict(final, train)
sqrt(mean((train$medv-P1)^2))


P2<- predict(final, test)
sqrt(mean((test$medv-P2)^2))

P2<- predict(linear, test)
sqrt(mean((test$medv-P2)^2))
```



## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B28-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ii, jj, kk, ll, ff, xxB26Hdesc, xxB26Hmod, xxB26Hraw, xxB26KC, namesXL)
```

```{r 'B28-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
