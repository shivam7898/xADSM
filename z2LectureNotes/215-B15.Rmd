# Quiz (B15, Oct-17) {#b15}

```{r 'B15', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Short Quiz

1. In hypothesis testing,
    a. the smaller the Type I error, the smaller the Type II error will be
    a. the smaller the Type I error, the larger the Type II error will be
    a. Type II error will not be affected by Type I error
    a. the sum of Type I and Type II errors must equal to 1
	  - Answer: \textcolor{black}{b}
1. What type of error occurs if you accept ${H_0}$ when, in fact, it is not true
    a. Type II
    a. Type I
    a. either Type I or Type II, depending on the level of significance
    a. either Type I or Type II, depending on whether the test is one tail or two tail
	  - Answer: \textcolor{black}{a}
1. If the level of significance of a hypothesis test is raised from .01 to .05, the probability of a Type II error
    a. will also increase from .01 to .05
    a. will not change
    a. will decrease
    a. will increase
	  - Answer: \textcolor{black}{c}
1. The sum of the values of ${\alpha}$ and ${\beta}$
    a. always add up to 1.0
    a. always add up to 0.5
    a. is the probability of Type II error
    a. None of these alternatives is correct
	  - Answer: \textcolor{black}{d}
1. Following the p-value approach, the null hypothesis is rejected if 
    a. p-value less than or equal to ${\alpha}$
    a. ${\alpha}$ < p-value
    a. p-value > ${\alpha}$
    a. p-value = 1 - ${\alpha}$
	  - Answer: \textcolor{black}{a}
1. The average manufacturing work week in metropolitan Chattanooga was 40.1 hours last year. It is believed that the recession has led to a reduction in the average work week. To test the validity of this belief, which of the following stated hypothesis formulation is true.
    a. ${H_0} : {\mu} < 40.1 \quad {H_a} : {\mu} \geq 40.1$
    a. ${H_0} : {\mu} \geq 40.1 \quad {H_a} : {\mu} < 40.1$
    a. ${H_0} : {\mu} > 40.1 \quad {H_a} : {\mu} \leq 40.1$
    a. ${H_0} : {\mu} = 40.1 \quad {H_a} : {\mu} \neq 40.1$
	  - Answer: \textcolor{black}{b}
1. Statement about a population developed for the purpose of testing is called:
    a. Hypothesis
    a. Hypothesis testing
    a. Level of significance
    a. Test-statistic
	  - Answer: \textcolor{black}{a}
1. The probability of rejecting the null hypothesis when it is true is called: 
    a. Level of confidence
    a. Level of significance
    a. Power of the test
    a. Difficult to tell
	  - Answer: \textcolor{black}{b}
1. The dividing point between the region where the null hypothesis is rejected and the region where it is not rejected is said to be:
    a. Critical region
    a. Critical value
    a. Acceptance region
    a. Significant region
	  - Answer: \textcolor{black}{b}
1. If the critical region is located equally in both sides of the sampling distribution of test-statistic, the test is called:
    a. One tailed
    a. Two tailed
    a. Right tailed
    a. Left tailed
	  - Answer: \textcolor{black}{b}
1. Test of hypothesis ${H_0}$: ${\mu} \leq 50$ against ${H_a}$: ${\mu} > 50$ leads to:
    a. Left-tailed test
    a. Right-tailed test
    a. Two-tailed test
    a. Difficult to tell
	  - Answer: \textcolor{black}{b}
1. Test of hypothesis ${H_0}$: ${\mu} = 20$ against ${H_1}$: ${\mu} < 20$ leads to:
    a. Right one-sided test
    a. Left one-sided test
    a. Two-sided test
    a. All of the above
	  - Answer: \textcolor{black}{b}
1. A failed student has been promoted by an examiner; it is an example of: 
    a. Type-I error
    a. Type-II error
    a. Unbiased decision
    a. Difficult to tell
	  - Answer: \textcolor{black}{b}
1. The probability of accepting ${H_0}$ when it is True is called: 
    a. Power of the test
    a. Size of the test
    a. Level of confidence
    a. Confidence coefficient
	  - Answer: \textcolor{black}{d}
1. Power of a test is directly related to:
    a. Type-I error
    a. Type-II error
    a. Both (a) and (b)
    a. Neither (a) nor (b)
	  - Answer: \textcolor{black}{b}
  
## Case: JAT 

\textcolor{pink}{Please import the Jayalaxmi data.}


```{r 'B15-Jnames', include=FALSE}
# #Object Names for each sheet
namesJ <- c("xxJdata", "xxJbela", "xxJdhar", "xxJdiseases")
```

```{r 'B15-Jaya', include=FALSE, eval=FALSE}
# #Path of Object, FileName and MD5Sum
xxJaya <- f_getObject("xxJaya", "B15-Jayalaxmi.xlsx", "8be20492c0181d2269754b3232b992aa")
```

```{r 'B15-Jobjects', include=FALSE, eval=FALSE}
# #Create Separate Tibbles for Each Sheet
# #Separate Objects
for(ii in seq_along(namesJ)){
  assign(namesJ[ii], xxJaya[[ii + 1]])
}
#
# #Modifications
# #Rename Headers
names(xxJdiseases) <- c("Type", "Disease", "RH", "Temperature")
# #Delete First Row
xxJdiseases <- xxJdiseases[-1, ]
#
# #Save Binary Files
for(ii in seq_along(namesJ)){
  saveRDS(eval(parse(text = namesJ[ii])), paste0(.z$XL, namesJ[ii], ".rds"))
}
```

```{r 'B15-ImportData', include=FALSE}
for(ii in seq_along(namesJ)){
  assign(namesJ[ii], readRDS(paste0(.z$XL, namesJ[ii], ".rds")))
}
```

```{r 'B15-List', include=FALSE}
# #Dimensions of these datasets
str(lapply(namesJ, function(x) {dim(eval(parse(text = x)))}))
```

```{r 'B15-List-A', ref.label=c('B15-Jnames', 'B15-List')}
#
```

> ERROR: THE CHUNK WAS NOT INCLUDED because of B- Names

### Trends {.tabset .tabset-fade}

#### Images {.unlisted .unnumbered}

```{r 'B15-ImageData', include=FALSE}
bb <- xxJdata %>% rename(Dates = "Month-Year", Users = "No of users") %>% 
  mutate(across(Dates, as_date)) %>% select(Dates, Week, Usage, Users)
#
ii <- bb %>% 
  mutate(NewDate = case_when(Week == "Week1" ~ Dates, Week == "Week2" ~ Dates + 7, 
                             Week == "Week3" ~ Dates + 14, Week == "Week4" ~ Dates + 21)) %>% 
  mutate(DIFF = c(1, diff(NewDate)), 
         TF = ifelse(DIFF > 10, FALSE, TRUE), 
         grp = cumsum(DIFF > 10) + 1)
#
str(ii)
```

```{r 'B15-UsageTrend', include=FALSE}
# #Plot
hh <- ii
title_hh <- "Usage Pattern"
caption_hh <- "B15P01"
#
B15 <- hh %>% {
  ggplot(data = ., aes(x = NewDate, y = Usage)) +
  geom_point() +
  #geom_smooth(aes(group = grp)) +
  geom_line(aes(group = grp)) +
  scale_x_date(date_breaks = "3 months", 
                labels = function(x) if_else(is.na(lag(x)) | !year(lag(x)) == year(x), 
                                             paste(month(x, label = TRUE), "\n", year(x)), 
                                             paste(month(x, label = TRUE)))) +
  labs(x = "Time", y = "Usage", 
       caption = caption_hh, title = title_hh)
}
assign(caption_hh, B15)
rm(B15)
```

```{r 'B15P01-Save', include=FALSE}
loc_png <- paste0(.z$PX, "B15P01", "_JAT_Usage", ".png")
if(!file.exists(loc_png)) ggsave(loc_png, plot = B15P01)
```

```{r 'B15P01', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B15P01", "_JAT_Usage", ".png"))
```

```{r 'B15-UserTrend', include=FALSE}
# #Plot
hh <- ii
title_hh <- "User Pattern"
caption_hh <- "B15P02"
#
B15 <- hh %>% {
  ggplot(data = ., aes(x = NewDate, y = Users)) +
  geom_point() +
  #geom_smooth(aes(group = grp)) +
  geom_line(aes(group = grp)) +
  scale_x_date(date_breaks = "3 months", 
                labels = function(x) if_else(is.na(lag(x)) | !year(lag(x)) == year(x), 
                                             paste(month(x, label = TRUE), "\n", year(x)), 
                                             paste(month(x, label = TRUE)))) +
  labs(x = "Time", y = "Users", 
       caption = caption_hh, title = title_hh)
}
assign(caption_hh, B15)
rm(B15)
```

```{r 'B15P02-Save', include=FALSE}
loc_png <- paste0(.z$PX, "B15P02", "_JAT_Users", ".png")
if(!file.exists(loc_png)) ggsave(loc_png, plot = B15P02)
```

```{r 'B15P02', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B15P02", "_JAT_Users", ".png"))
```

```{r 'B15P0102', echo=FALSE, ref.label=c('B15P01', 'B15P02'), fig.cap="JAT: Usage and Users over the TimePeriod"}
#
```

#### Data {.unlisted .unnumbered}

```{r 'B15-ImageData-A', ref.label=c('B15-ImageData')}
#
```

#### Trendline {.unlisted .unnumbered}

```{r 'B15-UsageTrend-A', ref.label=c('B15-UsageTrend'), eval=FALSE}
#
```

#### Skip Missing Data {.unlisted .unnumbered}

```{r 'B15-MissingDataTrendLine'}
bb <- xxJdata %>% rename(Dates = "Month-Year", Users = "No of users") %>% 
  mutate(across(Dates, as_date)) %>% select(Dates, Week, Usage, Users)
#
ii <- bb %>% 
  mutate(NewDate = case_when(Week == "Week1" ~ Dates, Week == "Week2" ~ Dates + 7, 
                             Week == "Week3" ~ Dates + 14, Week == "Week4" ~ Dates + 21)) %>% 
  mutate(DIFF = c(1, diff(NewDate)), 
         TF = ifelse(DIFF > 10, FALSE, TRUE), 
         grp = cumsum(DIFF > 10) + 1) %>% 
  mutate(grp_step = rle(TF)$lengths %>% {rep(seq(length(.)), .)})
#
jj <- c(1, which(ii$DIFF > 10), nrow(ii) + 1)
kk <- rep(1:length(diff(jj)), diff(jj))
stopifnot(identical(kk, as.integer(ii$grp)))
#
# #Where are the missing values
ii %>% filter( !TF | lead(!TF) | lag(!TF) )
```

### Q1 {.tabset .tabset-fade}

Test the claim that disease 6 (leaf curl) information was accessed at least 60 times every month on average since October 2017 due to this disease outbreak. $({\alpha} = 0.05)$

```{r 'B15D01', comment="", echo=FALSE, results='asis'}
f_getDef("Hypothesis-1T-Upper-Tail")
```

- ${}^U\!P_{t = 5.3771} = 0.0005 \to {}^U\!P_{(z)} < {\alpha} \to {H_0}$ is rejected
  - We can conclude that the information on disease 6 was accessed at least 60 times every month on average since October 2017.

#### Code {.unlisted .unnumbered}

```{r 'B15-Q1'}
# #Data | Rename | Sum Months D6 | Change from Date Time to Date
bb <- xxJdata %>% 
  rename(Dates = "Month-Year") %>% 
  group_by(Dates) %>% 
  summarise(D6 = sum(D6)) %>% 
  mutate(across(Dates, as_date)) 
# 
# #There are missing months, but those months are not applicable in this question
ii <- bb %>% filter(Dates >= "2017-10-01")
#
t_ii <- {mean(ii$D6) - 60} / {sd(ii$D6) / sqrt(nrow(ii))}
print(t_ii)
pt(t_ii, df = nrow(ii) - 1, lower.tail = FALSE)
#
# #One Sample t-Test
t.test(ii$D6, mu = 60, alternative = "greater", conf.level = 0.05)
```


#### Missing Months {.unlisted .unnumbered}

```{r 'B15-MissingMonths'}
str(bb)
summary(bb)
#
# #Assuming each row is one month with no duplicates
stopifnot(identical(anyDuplicated(bb$Dates), 0L))
#
# #Create Sequence of Months
#ii <- seq(ymd("2015-6-1"), ymd("2018-5-1"), by = "months")
ii <- tibble(Dates = seq(min(bb$Dates), max(bb$Dates), by = "months"))
#
diff_len <- nrow(ii) - nrow(bb)
#
if(!identical(diff_len, 0L)) {
  cat(paste0("Number of missing months = ", diff_len,"\n"))
  #
  # #Find Values that should be in Complete Sequence but are missing in the data
  as_date(setdiff(ii$Dates, bb$Dates))
  # #OR
  ii %>% anti_join(bb)
  #
  # #This does not need a separate Vector of all Months
  # #Get Months Difference using Integer Division and 
  # #Filter Rows which are not consecutive and rows above them
  bb %>% 
    mutate(diff_months = (interval(lag(Dates), Dates)) %/% months(1)) %>% 
    filter( (diff_months != 1) | lead(diff_months != 1) )
}
```


```{r 'B15-FillMissingMonths'}
# #Fill Missing Months 
jj <- as_tibble(merge(bb, ii, by = "Dates", all = TRUE)) 
kk <- right_join(bb, ii, by = "Dates") %>% arrange(Dates)
stopifnot(identical(jj, kk))
# #Replace NA 
ll <- kk %>% mutate(across(D6, coalesce, 0)) 
```


### Q2 {.tabset .tabset-fade}

Test the claim that Among the app users for disease information, at least 15% of them access disease information related to disease 6. $({\alpha} = 0.05)$

```{r 'B15D02', comment="", echo=FALSE, results='asis'}
f_getDef("Hypothesis-1T-Upper-Tail")
```

- ~~One Tail t-Test~~ \textcolor{orange}{Caution: Proportion Test is needed.} 
  - Wrong Analysis: 
    - ${}^U\!P_{t} = 0.094 \to {}^U\!P_{(t)} > {\alpha} \to {H_0}$ cannot be rejected.
    - ~~We cannot conclude that at least 15% of users access D6 related information.~~
  - (Aside) Why using t-test is wrong here 
    - 15% is NOT the ${\mu}$, it is proportion. Using that as Mean was wrong.
    - We are NOT looking for percentage of D6 lookup in each row or observation. It does not matter if one day farmers only looked for other diseases and another day farmers searched only D6. We are interested in overall share of D6 searches out of searches for Diseases

- Proportion Test

Determine whether the proportion of farmers searching for D6 is more than $p_0 = 0.15$

```{r 'B15D03', comment="", echo=FALSE, results='asis'}
f_getDef("H-1s-p-Upper")
```

- Count of Success $({x})$ is Searches of D6 
- $\{n = 26830, x = 4295\} \to {\overline{p}} = {n}/{x} = 0.160082$ 
- \@ref(eq:z-1s-p) 
  - ${}^U\!P_{({\chi}^2)} < {\alpha} \to {H_0}$ is rejected i.e. the proportions are different
  - We can conclude that the proportion of farmers searching for D6 is more than $p_0 = 0.15$ for all searches for Diseases.

#### Proportion Test {.unlisted .unnumbered}

```{r 'B15-PropTest'}
# #Data | Sum Disease, Variety, Micronutrients 
aa <- xxJdata %>% 
  mutate(sumD = rowSums(across(starts_with("D"))), 
         sumV = rowSums(across(starts_with("V")))) %>% 
  rename(Dates = "Month-Year", Users = "No of users", Micro = "Micronutrient") %>% 
  mutate(SUM = rowSums(across(c(sumD, sumV, Micro))),
         DIFF = Usage - SUM) %>% 
  select(Dates, Users, Usage, SUM, DIFF, sumD, sumV, Micro, D6) %>% 
  mutate(across(Dates, as_date)) %>% 
  mutate(Fraction = D6/sumD)
#
# #Confirmed that Usage is Sum Total of Disease, Variety, Micronutrients
unique(aa$DIFF)
#
# #Working Set | Exclude 1 NA i.e. where sumD is zero
bb <- aa %>% drop_na(Fraction) %>% select(Usage, sumD, D6, Fraction)
#
# #Check n (Sample Count) and x (Count of Success)
bb %>% summarise(across(c(sumD, D6), sum))
#
# #One Sample Proportion Test with continuity correction
bb_prop <- prop.test(x = sum(bb$D6), n = sum(bb$sumD), p = 0.15, 
                     alternative = "greater", conf.level = 0.95)
bb_prop
```

#### Proportion Test (Usage) {.unlisted .unnumbered}

```{r 'B15-PropTestALL'}
# #Impact if we try to evaluate propotion of D6 searches out of ALL Usage (Disease, Variety, Micro)
# #Check n (Sample Count) and x (Count of Success)
bb %>% summarise(across(c(Usage, D6), sum))
#
# #One Sample Proportion Test with continuity correction
# #With p-value = 1, we cannot claim that 15% searches are for D6 only out of ALL Usage
prop.test(x = sum(bb$D6), n = sum(bb$Usage), p = 0.15, 
                     alternative = "greater", conf.level = 0.95)
```

#### One Sample t-Test {.unlisted .unnumbered}

```{r 'B15-Q2-Wrong'}
# #One Sample t-Test
t.test(bb$Fraction, mu = 0.15, alternative = "greater", conf.level = 0.05)
```

### Q3 {.tabset .tabset-fade}

Test the claim that the average number of users in year 2017-2018 is more than average number of users in year 2015-2016. $({\alpha} = 0.05)$

```{r 'B15D04', comment="", echo=FALSE, results='asis'}
f_getDef("H-2s-Upper")
```

- If 1 is 2017-2018, 2 is 2015-2016 : Upper Tail Test is required
- If 1 is 2015-2016, 2 is 2017-2018 : Lower Tail Test is required
- Because the Variances are NOT same, Welch t-test is required, we cannot use Pooled Test
- $({}^L\!P_{t = -7.255} =  {}^U\!P_{t = 7.255}) < {\alpha} \to {H_0}$ is rejected 
  - The sample results provide sufficient evidence to conclude that the average number of users has increased.
- Also, Test the claim that app usage picked up after January 2016. (Moved from Q4)
  - ${}^U\!P_{t} < {\alpha} \to {H_0}$ is rejected 
  - The sample results provide sufficient evidence to conclude that the app usage has increased after January 2016.

- NOTE: Ideally, each missing month should have been added 4 times for the 4 weeks. "ForLater"

#### Code {.unlisted .unnumbered}

```{r 'B15-Q3'}
# #Data
bb <- xxJdata %>% 
  rename(Dates = "Month-Year", Users = "No of users") %>% 
  mutate(across(Dates, as_date)) %>% 
  select(Dates, Users, Usage)
#
# #Missing Months
ii <- tibble(Dates = seq(min(bb$Dates), max(bb$Dates), by = "months"))
jj <- right_join(bb, ii, by = "Dates") %>% arrange(Dates) %>% mutate(across(Users, coalesce, 0)) 
#
# #Create 2 Groups
jj$Year <- cut(jj$Dates, breaks = c(min(ii$Dates), as_date("2017-01-01"), Inf), 
               labels = c("2015-2016", "2017-2018"))
#
# #Verify Changes
jj[!duplicated(jj$Year), ]
jj %>% filter(Dates %in% ymd(c("2016-12-01", "2017-01-01")))
#
# #For Two Sample t-test, check if Variances are equal
jj_var <- var.test(Users ~ Year, data = jj)
jj_var
#
# #If Variances are Equal, Pooled Test otherwise Welch Test
isVarEqual <- ifelse(jj_var$p.value > 0.05, TRUE, FALSE)
#
# #Because 1 is "2015-2016", 2 is "2017-2018", we need to perform Lower Tail Test
jj_t <- t.test(formula = Users ~ Year, data = jj, alternative = "less", var.equal = isVarEqual)
jj_t
#
# #Alternatively, we can reverse Factor levels to perform Upper Tail Test
kk <- jj
kk$Year <- factor(kk$Year, levels = rev(levels(jj$Year)))
#
t.test(formula = Users ~ Year, data = kk, alternative = "greater", var.equal = isVarEqual)
```

#### 4b {.unlisted .unnumbered}

```{r 'B15-Q34b'}
# #Data
str(jj)
# #For Two Sample t-test, check if Variances are equal
jj_var <- var.test(Usage ~ Year, data = jj)
jj_var
#
# #If Variances are Equal, Pooled Test otherwise Welch Test
isVarEqual <- ifelse(jj_var$p.value > 0.05, TRUE, FALSE)
#
# #Because 1 is "2015-2016", 2 is "2017-2018", we need to perform Lower Tail Test
t.test(formula = Usage ~ Year, data = jj, alternative = "less", var.equal = isVarEqual)
```



### Q4 {.tabset .tabset-fade}

Check whether app usage is same or different across the four weeks of a month. 
Test the claim that app usage picked up after January 2016. (Answered with Q3)

```{r 'B15D05', comment="", echo=FALSE, results='asis'}
f_getDef("H-ANOVA")
```

- Data groups are not normal and neither the variances are equal
  - Log transformation failed, Residual Test failed
  - However, Sqrt transformation passed Normality Test as well as Variances are found to be same
- Using Sqrt of Data ${}^U\!P_{(F)} > {\alpha} \to {H_0}$ cannot be rejected 
  - The sample results do not provide sufficient evidence to conclude that the app usage is different across the four weeks of a month. 

#### Images {.unlisted .unnumbered}


```{r 'B15-QQPlot', include=FALSE}
bb <- xxJdata %>% 
  rename(Dates = "Month-Year", Users = "No of users") %>% 
  mutate(Week = factor(Week)) %>% 
  mutate(Sqrt = sqrt(Usage)) %>% 
  select(Week, Usage, Sqrt)
#
hh <- bb
title_hh <- "QQ Plot of Usage"
caption_hh <- "B15P04"
#
B15 <- hh %>% { ggplot(., aes(sample = Usage, colour = Week)) +
    stat_qq() +
    stat_qq_line() +
    labs(caption = caption_hh, title = title_hh)
}
assign(caption_hh, B15)
rm(B15)
#
title_hh <- "QQ Plot of Sqrt(Usage)"
caption_hh <- "B15P05"
B15 <- hh %>% { ggplot(., aes(sample = Sqrt, colour = Week)) +
    stat_qq() +
    stat_qq_line() +
    labs(caption = caption_hh, title = title_hh)
}
assign(caption_hh, B15)
rm(B15)
```


```{r 'B15P04-Save', include=FALSE}
loc_png <- paste0(.z$PX, "B15P04", "_JAT_QQ_Usage", ".png")
if(!file.exists(loc_png)) ggsave(loc_png, plot = B15P04)
```

```{r 'B15P04', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B15P04", "_JAT_QQ_Usage", ".png"))
```

```{r 'B15P05-Save', include=FALSE}
loc_png <- paste0(.z$PX, "B15P05", "_JAT_QQ_Usage_Sqrt", ".png")
if(!file.exists(loc_png)) ggsave(loc_png, plot = B15P05)
```

```{r 'B15P05', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B15P05", "_JAT_QQ_Usage_Sqrt", ".png"))  #iiii
```

```{r 'B15P04P05', echo=FALSE, ref.label=c('B15P04', 'B15P05'), fig.cap="JAT: QQ Plot of Usage and Sqrt(Usage)"}
#
```

#### Anova & Kruskal {.unlisted .unnumbered}

```{r 'B15-Q4'}
# #Data | Missing Months can be ignored because those are missing across all weeks
bb <- xxJdata %>% 
  rename(Dates = "Month-Year", Users = "No of users") %>% 
  select(Week, Usage)
#
str(bb)
summary(bb)
#
# #ANOVA (on original data : neither normal, nor of equal variance)
bb_aov <- aov(formula = Usage ~ Week, data = bb)
#
# #
model.tables(bb_aov, type = "means")
#
# #Summary
summary(bb_aov)
#
bb_aov
#
kruskal.test(Usage ~ Week, data = bb)
#
# #Poisson Test (ForLater)
#anova(glm(Usage ~ Week, data = ii, family = poisson), test = "LRT")
#
# #Transformation: Square Root Data
ii <- bb %>% mutate(Week = factor(Week)) %>% mutate(Sqrt = sqrt(Usage))
str(ii)
summary(ii)
#
# #ANOVA
ii_aov <- aov(formula = Sqrt ~ Week, data = ii)
# #
model.tables(ii_aov, type = "means")
#
# #Summary
summary(ii_aov)
#
kruskal.test(Sqrt ~ Week, data = ii)
```

#### Variance {.unlisted .unnumbered}

[(External) Variances in R](http://www.sthda.com/english/wiki/compare-multiple-sample-variances-in-r "http://www.sthda.com")

Statistical tests for comparing the variances of two or more samples. Equal variances across samples is called homogeneity of variances.

- Reason
  - Two independent samples T-test and ANOVA test, assume that variances are equal across groups. 
- Statistical tests for comparing variances
  - F-test: Compare the variances of two samples. The data must be normally distributed.
  - Bartlett test: Compare the variances of k samples, where k can be more than two samples. 
    - The data must be normally distributed. 
    - The Levene test is an alternative to the Bartlett test that is less sensitive to departures from normality.
  - Levene test: Compare the variances of k samples, where k can be more than two samples. 
    - It is an alternative to the Bartlett test that is less sensitive to departures from normality.
  - Fligner-Killeen test: a non-parametric test which is very robust against departures from normality.
- Hypothesis
  - For all these tests (Bartlett test, Levene test or Fligner-Killeen test): 

```{definition 'H-Variances'}
\textcolor{pink}{$\text{\{Variances\}} {H_0} : {\sigma}_1 = {\sigma}_2 = \dots = {\sigma}_k \iff {H_a}: \text{At least two variances differ.}$}
```

- On this data, all 3 tests have p-value less than 0.05, i.e. Variances are NOT same
- On the Transformed Data (Sqrt), Levene Test and Fligner Test fail to detect difference in Variances


```{r 'B15-Variance'}
# #Data
str(bb)
summary(bb)
#
# #Bartlett Test
bartlett.test(Usage ~ Week, data = bb)
#
# #Levene Test
ii <- bb %>% mutate(Week = factor(Week))
leveneTest(Usage ~ Week, data = ii)
#
# #Fligner-Killeen test
fligner.test(Usage ~ Week, data = bb)
#
# #Transformation: Square Root Data
ii <- bb %>% mutate(Week = factor(Week)) %>% mutate(Sqrt = sqrt(Usage))
bartlett.test(Sqrt ~ Week, data = ii)
leveneTest(Sqrt ~ Week, data = ii)
fligner.test(Sqrt ~ Week, data = ii)
```


#### Normality {.unlisted .unnumbered}

```{r 'B15-Normality'}
# #Are the data from each of the 4 groups follow a normal distribution
# #Shapiro-Wilk normality test
bb %>% mutate(Week = factor(Week)) %>% 
  group_by(Week) %>% 
  summarise(N = n(), Mean = mean(Usage), SD = sd(Usage),
            p_Shapiro = shapiro.test(Usage)$p.value, 
            isNormal = ifelse(p_Shapiro > 0.05, TRUE, FALSE))
# #Check Q-Q plot
#qqnorm(bb[bb$Week == "Week1", ]$Usage)
#
# #Transformation: Log (Did not pass Normality)
bb %>% mutate(Week = factor(Week)) %>% 
  mutate(Log = log(Usage)) %>% 
  group_by(Week) %>% 
  summarise(p_Shapiro = shapiro.test(Log)$p.value, 
            isNormal = ifelse(p_Shapiro > 0.05, TRUE, FALSE))
#
# #Transformation: Square Root (Success: Passed Normality) - Selected
bb %>% mutate(Week = factor(Week)) %>% 
  mutate(Sqrt = sqrt(Usage)) %>% 
  group_by(Week) %>% 
  summarise(p_Shapiro = shapiro.test(Sqrt)$p.value, 
            isNormal = ifelse(p_Shapiro > 0.05, TRUE, FALSE))
#
# #Transformation: Cube Root (Success: Passed Normality) Just to check
bb %>% mutate(Week = factor(Week)) %>% 
  mutate(CubeRoot = Usage^(1/3)) %>% 
  group_by(Week) %>% 
  summarise(p_Shapiro = shapiro.test(CubeRoot)$p.value, 
            isNormal = ifelse(p_Shapiro > 0.05, TRUE, FALSE))
#
# #Testing Residuals i.e. Data - Group Mean (Did not pass Normality)
bb %>% mutate(Week = factor(Week)) %>% 
  group_by(Week) %>% 
  mutate(Residuals = Usage - mean(Usage)) %>% 
  summarise(p_Shapiro = shapiro.test(Residuals)$p.value, 
            isNormal = ifelse(p_Shapiro > 0.05, TRUE, FALSE))

```

#### QQ Plot {.unlisted .unnumbered}

```{r 'B15-QQPlot-A', eval=FALSE, ref.label=c('B15-QQPlot')}
#
```

### Q5 {.tabset .tabset-fade}

```{r 'B15D06', comment="", echo=FALSE, results='asis'}
f_getDef("H-2s-Upper") 
```

A new version of the app was released in August-2016. Which month in the given time frame after the launch of the new version, the mean usage pattern would start to show a statistically significant shift

- (1: OldApp, 2: NewApp) Lower Tail Test is required
- Because the Variances are NOT same, Welch t-test is required, we cannot use Pooled Test
- ${}^L\!P_{t} < {\alpha} \to {H_0}$ is rejected 
  - The sample results provide sufficient evidence to conclude that the mean usage has increased after August-2016.
  
#### Basic {.unlisted .unnumbered}

```{r 'B15-Q5'}
# #Data
bb <- xxJdata %>% rename(Dates = "Month-Year") %>% mutate(across(Dates, as_date)) %>% 
  select(Dates, Week, Usage)
#
# #Create 2 Groups
bb$Year <- cut(bb$Dates, breaks = c(min(bb$Dates), as_date("2016-08-01"), Inf), 
               labels = c("OldApp", "NewApp"))
#
# #For Two Sample t-test, check if Variances are equal
bb_var <- var.test(Usage ~ Year, data = bb)
bb_var
#
# #If Variances are Equal, Pooled Test otherwise Welch Test
isVarEqual <- ifelse(bb_var$p.value > 0.05, TRUE, FALSE)
#
# #Because 1 is "OldApp", 2 is "NewApp", we need to perform Lower Tail Test
bb_t <- t.test(formula = Usage ~ Year, data = bb, alternative = "less", var.equal = isVarEqual)
bb_t
#
```

#### rollapply() {.unlisted .unnumbered}

```{r 'B15-Q5b'}
# #Rolling Sums
old_sd <- sd(bb[bb$Year == "OldApp", ]$Usage)
old_n <- summary(bb$Year)[1]
#
ii <- bb %>% filter(Year == "NewApp", Dates <= '2017-05-01') %>% select(-Year)
#
jj <- ii %>% mutate(ID = row_number(), cSUM = cumsum(Usage), cMean = cSUM/ID) %>% 
  mutate(SD = across(Usage, ~ rollapply(., ID, sd, fill = NA, align = "right"))) %>% 
  mutate(DOF = floor({SD^2 / ID + old_sd^2 / old_n }^2 / 
                       {{SD^2 / ID}^2/{ID-1} + {old_sd^2 / old_n}^2/{old_n-1}})) %>% 
  mutate(Sigma = sqrt({SD^2 /ID + old_sd^2 /old_n}))
str(jj)
```


### Q6 {.tabset .tabset-fade}

If a disease is likely to spread in particular weather condition (data given in the disease index sheet), then the access of that disease should be more in the months having suitable weather conditions. Help the analyst in coming up with a statistical test to support the claim for two districts for which the sample of weather and disease access data is provided in the data sheet. Identify the diseases for which you can support this claim. Test this claim both for temperature and relative humidity at 95% confidence.

```{r 'B15D07', comment="", echo=FALSE, results='asis'}
f_getDef("H-2s-Upper") #dddd
```


```{r 'B15-Q6', include=FALSE}
# #Merge both dataframes of Two districts
aa <- bind_rows(Belagavi = xxJbela, Dharwad = xxJdhar, .id = 'source') %>% 
  rename(Dates = Months, RH = "Relative Humidity", TMP = "Temperature") %>% 
  mutate(across(Dates, as_date)) %>% mutate(source = factor(source)) %>% 
  select(-c(10:13)) %>% select(-D6)
#
# #Based on Conditional T & RH, get each disease favourable condition = TRUE
q6_bb <- aa %>% mutate(iD1 = ifelse(TMP <= 24 & TMP >= 20 & RH > 80, TRUE, FALSE), 
                    iD2 = ifelse(TMP <= 24.5 & TMP >= 21.5 & RH > 83, TRUE, FALSE), 
                    iD3 = ifelse(TMP <= 24 & TMP >= 22, TRUE, FALSE), 
                    iD4 = ifelse(TMP <= 26 & TMP >= 22 & RH > 85, TRUE, FALSE), 
                    iD5 = ifelse(TMP <= 24.5 & TMP >= 22 & RH <= 85 & RH >= 77, TRUE, FALSE), 
                    iD7 = ifelse(TMP > 25 & RH > 80, TRUE, FALSE)) %>% 
  mutate(across(starts_with("i"), factor, levels = c(TRUE, FALSE)))
bb <- q6_bb
#
# #Create all Formulae for variance and t-test
formulas <- paste0(names(bb)[3:8], " ~ ", names(bb)[11:16])
#
# #Appply formulae
output <- t(sapply(formulas, function(f) {
    test_var <- var.test(as.formula(f), data = bb)
    isVarEqual <- ifelse(test_var$p.value > 0.05, TRUE, FALSE) 
    test_t <- t.test(as.formula(f), data = bb, alternative = "greater", var.equal = isVarEqual)
    c("p- Var" = format(round(test_var$p.value, 5), scientific = FALSE), 
      "Equal Var" = ifelse(test_var$p.value > 0.05, TRUE, FALSE), 
      "p- t-test" = format(round(test_t$p.value, 5), scientific = FALSE), 
      "Upper H0" = ifelse(test_t$p.value > 0.05, "Not Rejected", "Rejected"))
}))
```

```{r 'B15T01', echo=FALSE}
bb <- output
kbl(bb,
  caption = "(B15T01) Q6: Diseases p-value (Upper)",
  #col.names = displ_names,
  escape = FALSE, align = "c", booktabs = TRUE
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                html_font = "Consolas",	font_size = 12,
                full_width = FALSE,
                #position = "float_left",
                fixed_thead = TRUE
  ) %>%
	row_spec(0, color = "white", background = "#303030", bold = TRUE,
	         extra_css = "border-bottom: 1px solid; border-top: 1px solid"
	)
```

- (1: Conditions Favourable for Disease i.e. TRUE, 2: FALSE) Upper Tail Test is required
- Testing variance and applying Welch t-test (variances not same) or Pooled Test (variances are same)
- Assuming both districts to be part of same sample
- Values are given in the \@ref(tab:B15T01)
  - ${}^U\!P_{t} > {\alpha} \to {H_0}$ cannot be rejected for disease 4
  - ${}^U\!P_{t} < {\alpha} \to {H_0}$ is rejected for diseases 1, 2, 3, 5, and 7
  - The sample results provide sufficient evidence to conclude that the claim is True for diseases 1, 2, 3, 5, and 7

#### BoxPlot {.unlisted .unnumbered}

```{r 'B15-BoxPlot', include=FALSE}
bb <- q6_bb
hh <- q6_bb %>% 
  rename_with(~gsub("iD", "i", .x)) %>% 
  select(starts_with(c("D", "i"))) %>% 
  select(-Dates) %>% 
  pivot_longer(everything(), names_to = c(".value", "Disease"), names_pattern = "(.)(.)") %>%
  rename(Values = "D", Favourable = "i")
#
title_hh <- "BoxPlot of Searches for Diseases in both districts"
caption_hh <- "B15P03"
#
B15 <- hh %>% { ggplot(data = ., mapping = aes(x = Disease, y = Values, fill = Favourable)) +
        geom_boxplot(outlier.shape = NA) +
        #stat_summary(fun = mean, geom = "point", size = 2, color = "steelblue") + 
        #scale_y_continuous(breaks = seq(0, 110, 10), limits = c(0, 110)) +
        geom_point(position = position_jitterdodge(jitter.width = 0.1), 
                   size = 1, alpha = 0.7, colour = "#21908CFF") + 
        k_gglayer_box +
        theme(
            #legend.justification = c("right", "top"),
            #legend.box.just = "right",
            #legend.margin = margin(6, 6, 6, 6),
            legend.position = c(.90, .95)
        ) +
        labs(x = "Diseases", y = "Searches per month", fill = "Favourable",
             caption = caption_hh, title = title_hh)
}
assign(caption_hh, B15)
rm(B15)
```

```{r 'B15P03-Save', include=FALSE}
loc_png <- paste0(.z$PX, "B15P03", "_JAT_Diseases", ".png")
if(!file.exists(loc_png)) ggsave(loc_png, plot = B15P03)
```

```{r 'B15P03', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B15P03", "_JAT_Diseases", ".png"))
```

```{r 'B15P03-A', echo=FALSE, ref.label=c('B15P03'), fig.cap="JAT: Disease Searches grouped with Faourable and unfavourable Condisions (T and RH)"}
#
```

#### Code {.unlisted .unnumbered}

```{r 'B15-Q6-A', ref.label=c('B15-Q6'), eval=FALSE}
#
```

#### BoxPlot More {.unlisted .unnumbered}

```{r 'B15-BoxPlot-A', ref.label=c('B15-BoxPlot'), eval=FALSE}
#
```

#### Pattern Match {.unlisted .unnumbered}

```{r 'B15-Pattern'}
# #rename_with() uses formula
# #Selection Helpers like starts_with() can take multiple conditions
# #pivot_longer() can return multiple groups
# #Pattern Match: Both First and Second Pattern can contain only 1 character
ii <- q6_bb %>% 
  rename_with(~gsub("iD", "i", .x)) %>% 
  select(starts_with(c("D", "i"))) %>% select(-Dates) %>% 
  pivot_longer(everything(), names_to = c(".value", "Disease"), names_pattern = "(.)(.)") %>%
  rename(Values = "D", Favourable = "i")
#
# #First Pattern can contain 1 or more characters but the Second can have only 1 character
jj <- q6_bb %>% 
  select(starts_with(c("D", "i"))) %>% select(-Dates) %>% 
  pivot_longer(everything(), names_to = c(".value", "Disease"), names_pattern = "(.*)(.)") %>% 
  rename(Values = "D", Favourable = iD)
stopifnot(identical(ii, jj))
```


## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B15-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ee, hh, ii, jj, kk, ll, mm, nn, oo, rr, vv, xx, yy, zz, bb_aov, bb_prop, 
          diff_len, ii_aov, isVarEqual, jj_t, jj_var, namesJ, t_ii, xxJbela, xxJdata, xxJdhar,
          xxJdiseases, B15P01, B15P02, bb_t, bb_var, caption_hh, loc_png, title_hh, B15P03, 
          formulas, old_n, old_sd, output, q6_bb, B15P04, B15P05)
```

```{r 'B15-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
