# Logistic Regression (B34, Feb-27) {#b34}

```{r 'B34', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Packages

```{r 'B34-Installations', include=FALSE, eval=FALSE}
if(FALSE){# #WARNING: Installation may take some time.
  install.packages("ROSE", dependencies = TRUE)
}
```

## Data: Bank {#set-bank-b34 .tabset .tabset-fade}

### Glance {.unlisted .unnumbered}

\textcolor{pink}{Please import the "B34-bank-full.csv"}

- About: Bank [45211, 17]
  - 'y' is the Response Variable: has the client subscribed a term deposit
    - Goal is to estimate /predict if the client will subscribe a bank term deposit
  - default: has credit in default (categorical: "no", "yes")
  - balance: Its description is not known yet - "ForLater"
    - It can be negative also
  - housing: has housing loan (categorical: "no", "yes")
  - loan: has personal loan (categorical: "no", "yes")
  - related with the last contact of the current campaign:
    - day: It looks like the date of the month because [1, 31]
    - month: corresponding month
    - duration: last contact duration, in seconds (numeric). 
      - \textcolor{orange}{Caution:} This attribute highly affects the output target (e.g., if duration=0 then y="no"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
  - other attributes:
    - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
    - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
      - 36954 / 45211 values are "-1"
    - previous: number of contacts performed before this campaign and for this client (numeric)
      - For those 36954 records, this value is "0"
      - Maximum contacts performed for a client are 275 whereas 2nd highest is 58
    - poutcome: outcome of the previous marketing campaign (categorical)
      - It is "unknown" for those 36954 records and 5 more records
      - The "other" should be merged with "unknown"


```{r 'B34-Data-Bank', include=FALSE, eval=FALSE}
# #Path of Object, FileName and MD5Sum tools::md5sum(paste0(.z$XL, "B34-bank-full.csv"))
#xxB34Bank <- f_getObject("xxB34Bank", "B34-bank-full.csv",
                                #"e6b0ca77f3f200ec5428e04dd104da53")
loc_src <- paste0(.z$XL, "B34-bank-full", ".csv")
loc_rds <- paste0(.z$XL, "xxB34Bank", ".rds")
tbl <- read_delim(file = paste0(.z$XL, "B34-bank-full.csv"), delim = ";")
attr(tbl, "spec") <- NULL
attr(tbl, "problems") <- NULL
saveRDS(tbl, loc_rds)
```

```{r 'B34-Save-Bank', include=FALSE, eval=FALSE}
f_setRDS(xxB34Bank)
```

### EDA {.unlisted .unnumbered}

```{conjecture 'Tibble-Subset-NoMatrix'}
\textcolor{brown}{Error: The `i` argument of `[` ...}
```

- Cannot subset a Tibble using Matrix. Convert to a vector.

```{r 'B34-Modify-Bank', eval=FALSE}
xxB34Bank <- f_getRDS(xxB34Bank)
# #Factor | Relocate Response | Drop
zzB34Bank <- xxB34Bank %>% 
  #mutate(across(where(is.character) & !c(y), factor)) %>% 
  mutate(across(education, factor, 
                levels = c("primary", "secondary", "tertiary", "unknown"), 
                labels = c("I", "II", "III", "q"))) %>% 
  mutate(across(education, relevel, ref = "III")) %>% 
  rename(edu = education) %>% 
  mutate(across(marital, factor, 
                levels = c("married", "single", "divorced"), 
                labels = c("M", "S", "D"))) %>% 
  rename(wed = marital) %>% 
  mutate(across(contact, factor, 
                levels = c("cellular", "telephone", "unknown"), 
                labels = c("cell", "tele", "q"))) %>% 
  rename(call = contact) %>% 
  mutate(across(poutcome, factor, levels = c("failure", "success", "other", "unknown"), 
                           labels = c("fail", "pass", "q", "q"))) %>%  
  mutate(across(where(is.character), factor)) %>% 
  relocate(y) %>% 
  select(-c(job, month))
#
f_setRDS(zzB34Bank)
```


```{r 'B34-Get-Bank'}
zzB34Bank <- f_getRDS(zzB34Bank)
#
# #Create Dummies | Replaced All NA in original data so no replacement in dummy columns |
dum_xfw <- dummy_cols(zzB34Bank, 
  select_columns = c("wed", "edu", "default", "housing", "loan", "call", "poutcome"),
                      remove_first_dummy = TRUE, remove_selected_columns = TRUE) 
#
# #Partition Data
set.seed(3)
#idx_xsyw <- sample.int(n = nrow(dum_xfw), size = floor(0.8 * nrow(dum_xfw)), replace = FALSE)
idx_xsyw <- createDataPartition(dum_xfw$y, p = 0.8, list = FALSE)
train_xfw <- dum_xfw[idx_xsyw[, 1], ] 
test_xfw  <- dum_xfw[-idx_xsyw[, 1], ]
#
xbank <- train_xfw
test_bank <- test_xfw
```

### Structure {.unlisted .unnumbered}

```{r 'B34-Structure-Bank'}
str(xbank)
```

### Summary {.unlisted .unnumbered}

```{r 'B34-Summary-Bank'}
summary(xbank)
```


### ETC {.unlisted .unnumbered}

```{r 'B34-ETC', include=TRUE, eval=FALSE}
bb <- xfw
# #Count NA in Columns
if(FALSE) colSums(is.na(bb)) %>% as_tibble(rownames = "Cols") %>% filter(value > 0)
# #Subset Rows
if(FALSE) bb %>% select(1) %>% slice(1:10)
# #Comma separated string having each item within quotes for easy pasting as character not objects
if(FALSE) cat('"', paste0(names(which(sapply(bb, is.factor))), collapse = '", "'), '"\n', sep = '')
if(FALSE) cat('"', paste0(levels(bb$poutcome), collapse = '", "'), '"\n', sep = '')
# #Filter
if(FALSE) bb %>% filter(is.na(bpl)) %>% select(id, bph, bpl)
# #Count Yes/No or True/False in ALL such Columns
if(FALSE) bb %>% select(iFemale, iMarried) %>% 
  pivot_longer(everything()) %>% count(name, value) %>% 
  pivot_wider(names_from = value, values_from = n) 
# #Count Unique of all Columns to decide which should be Factors
if(FALSE) bb %>% summarise(across(everything(), ~ length(unique(.)))) %>% pivot_longer(everything())
# #Summary of Columns of a class: is.factor is.numeric is.character
if(FALSE) bb %>% select(where(is.factor)) %>% summary()
# #Names and Indices of Columns of class: is.factor is.numeric is.character
if(FALSE) which(sapply(bb, is.factor))
# #Levels of Factor Columns
if(FALSE) lapply(bb["poutcome"], levels)
if(FALSE) lapply(bb[c(3)], levels)
# #Frequency of Each level of Factor
if(FALSE) bb %>% count(poutcome) %>% arrange(desc(n))
# #Coding for Dummy Variables
if(FALSE) contrasts(bb$Married) 
```


## Logistic Regression

```{r 'B34D01', comment="", echo=FALSE, results='asis'}
f_getDef("Classification") #dddd
```

- Logistic Curve between Response and Predictor is S-shaped curve (sigmoid)
  - The most basic Logistic Function: $f(x) = \frac{1}{1+e^{-x}}$
  - Unlike, linear regression where this curve is a straight line with range of $(-\infty, +\infty)$
  - Because, the response calculated is a probability of belonging to a certain 'class', thus its range is (0, 1). 

- \textcolor{pink}{Question:} Can we convert a response variable of Continuous nature to Categorical
  - Yes, e.g. Sales, we can define a criteria of low, medium, high sales (Binning)
  - However, Generally conversion from categorical to continuous is either not possible or not meaningful

- \textcolor{pink}{Logistic Function: $p(X) = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} = \frac{\text{Odds}}{1 + \text{Odds}} \in [0, 1]$}

- \textcolor{pink}{$\text{Odds} = e^{\beta_0 + \beta_1 X} = \frac{p(X)}{1 - p(X)} \in [0, \infty]$}
  - The odds are defined as the probability that the event will occur divided by the probability that the event will not occur. 
    - If a race horse runs 100 races and wins 5 times and loses the other 95 times. $p(\text{win}) = 0.05 \leftrightarrow \text{odds}_{\text{win}} = \frac{0.05}{1 - 0.05} = 0.0526$.
  - If a race horse runs 100 races and wins 25 times and loses the other 75 times. $p(\text{win}) = 0.25 \leftrightarrow \text{odds}_{\text{win}} = \frac{0.25}{1 - 0.25} = 0.333$, or 1 win to 3 loses.
  - If a race horse runs 100 races and wins 50 times and loses the other 50 times. $p(\text{win}) = 0.50 \leftrightarrow \text{odds}_{\text{win}} = \frac{0.50}{1 - 0.50} = 1$, or \textcolor{pink}{even odds}.
  - If a race horse runs 100 races and wins 80 times and loses the other 20 times. $p(\text{win}) = 0.80 \leftrightarrow \text{odds}_{\text{win}} = \frac{0.80}{1 - 0.80} = 4$, or 4 win to 1 loses.

- \textcolor{pink}{Log odds or Logit: $\log\left( \frac{p(X)}{1 - p(X)} \right) = \beta_0 + \beta_1 X$}
  - Recall that in a linear regression model, $\beta_1$ gives the average change in Y associated with a one-unit increase in X. 
  - By contrast, in a logistic regression model, increasing X by one unit changes the log odds by $\beta_1$. Equivalently, it multiplies the odds by $e^{\beta_1}$. 
  - However, in logistic regression, because the relationship between p(X) and X is not a straight line, $\beta_1$ does not correspond to the change in p(X) associated with a one-unit increase in X. 
  - The amount that p(X) changes due to a one-unit change in X depends on the current value of X. But regardless of the value of X, if $\beta_1$ is positive then increasing X will be associated with increasing p(X), and if $\beta_1$ is negative then increasing X will be associated with decreasing p(X).

- \textcolor{pink}{Question:} What is the meaning of 0 logit or log odds (for a binary response)
  - $\log(\text{Odds}) = 0 \leftrightarrow \text{Odds} = 1 \leftrightarrow p(X) = 0.5$
  - It means equal odds for event or no-event. In other words, both outcome have equal probability.


- Binomial Logistic Regression has two classes or levels of Response variable.
- \textcolor{pink}{Multinomial logistic regression} extends the two-class logistic regression approach to the setting of K > 2 classes (response variable with more than two classes). 

- Like dummy, we select a class to serve as baseline.
- \textcolor{orange}{Caution:} By default, R takes the First class level as the baseline.

- To evaluate a logistic regression model, we use \textcolor{pink}{mis-classification error} because RMSE is not applicable.

## Confusion Matrix

- Refer [Confusion Matrix](#confusion-f67 "f67")

```{r 'B34T01', echo=FALSE, ref.label=c('F67T01')}
#
```

```{r 'B34E01', comment="", echo=FALSE, results='asis'}
f_getExm("Confusion-Setup")
```

```{r 'B34E02', comment="", echo=FALSE, results='asis'}
f_getExm("Confusion-Definitions")
```


## Imbalanced data: Impact on Model


```{definition 'Imbalanced-Data'}
\textcolor{pink}{Imbalanced Data} refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations. e.g. 333 defaulters and 9667 non-defaulters
```


- Effect of Imbalanced Data on the Model
  - Generally, in the case of logistic regression the data imbalance is present 
  - Thus, the model is generally biased towards the majority class

- Data Balancing is done by package ROSE
  - Oversampling
    - Bootstrapping with replacement on minority class 
    - e.g. 9667 non-defaulters and 9667 with bootstrapping defaulters (from 333)
  - Under-sampling
    - Random selection of majority class to match number of observations in minority class
    - e.g. 333 defaulters and 333 non-defaulters (from 9667)
  - Both
    - Both of the balancing techniques are applied with the given probability
    - e.g. if we request a dataset of 10,000 with probability of 0.5, then there will be approximately 5000 non-default observations selected randomly and approximately 5000 defaulters using bootstrapping

- \textcolor{pink}{Question:} Are we not fabricating the data with 'over sampling'
  - No, it is random selection
  - SMOTE (synthetic bootstrapping) - It will fabricate the data. It is more powerful.
  - "ForLater" More details required because in the earlier discussion, this question also was discussed
  - Similarly, problem with under sampling was loss of available information.
  - The solution suggested at the time was to achieve approximately 1:10 ratio between minority and majority classes.

## To be continued ...

- Discussion moved to next lecture: Logistic Regression on the Bank dataset


## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B34-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ii, jj, kk, ll, cap_hh, dum_xfw, hh, idx_xsyw, test_bank, test_xfw, train_xfw, 
          xbank, zzB34Bank)
```

```{r 'B34-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
