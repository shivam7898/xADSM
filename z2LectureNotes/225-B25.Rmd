# Regresssion (B25, Dec-26) {#b25 .unlisted .unnumbered}

```{r 'B25', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- "Supervised Learning Algorithm: Regression"
  - "ForLater"

## Linear Regression

```{definition 'Linear-Regression'}
\textcolor{pink}{Linear regression} is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables. 
```

- ${Y}$: Scalar response, Dependent variable, Outcome variable, Target, Predicted
- ${X}$: Explanatory variables, Independent variables, Antecendent variables, Predictors

- It is applied when the objective is to predict the outcome variable based on the antecendent variables
- Predicted can be continuous, but Predictors can be either continuous or categorical 
  - Ex: Salary (Y) is a function of Age, Gender, Education, Years of Experience
  - Ex: Consumption (Y) is a function of Income (X)
  - We are interested in $Y = mX + C$ where ${m}$ is the slope of the line and C is the y-intercept
  - Because there will be some error ${\epsilon}$, thus the equation is given by $y = {\alpha} + {\beta}x + {\epsilon}$ where ${\alpha}$ is the average Y when X are zero.





## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B25-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ii, jj, kk, ll)
```

```{r 'B25-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
