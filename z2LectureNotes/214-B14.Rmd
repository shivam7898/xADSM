# Statistics (B14, Oct-10) {#b14}

```{r 'B14', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- "Inferential Statistics: Hypothesis Testing"
  - [Equality in Hypothesis](#equality-b14 "b14")

## Equality in Hypothesis  {#equality-b14 .unlisted .unnumbered}

- The equality part of the expression $\{\mu \geq \mu_0 \, | \, \mu \leq \mu_0 \, | \, \mu = \mu_0\}$ \textcolor{pink}{always} appears in the null hypothesis ${H_0}$. 
  - We try to reject null, so that we can confidently accept the alternate. If the alternate is ambiguous e.g. "is greater than or equal to" then we will not be able to conclude with confidence.
- Alternative hypothesis is often what the test is attempting to establish.
  - Hence, asking whether the user is looking for evidence to support $\{\mu < \mu_0 \, | \, \mu > \mu_0 \, | \, \mu \neq \mu_0\}$ will help determine ${H_a}$


```{r 'B14D02', comment="", echo=FALSE, results='asis'}
f_getDef("1s-known-sd")
```

```{r 'B14D03', comment="", echo=FALSE, results='asis'}
f_getDef("1s-unknown-sd")
```


## Example: WSES: Preprocessing

\textcolor{pink}{Please import the WSES data in xxWSES object. Due to copyright, it has not been shared.}

```{r 'B14-xxWSES', include=FALSE, eval=FALSE}
# #Load Data: WSES
xxWSES <- f_getObject("xxWSES", "B13-WSES.csv", "772c81252c54a3162f1f8dbd0ceb9aeb")
if(FALSE) {
  loc_src <- paste0(.z$XL, "B13-WSES.xlsx")
  aa <- read_excel(path = loc_src, sheet = excel_sheets(path = loc_src)[2])
  str(aa)
}
```

- Assuming: Average Sales 8-million $({\mu}_0 = 8)$, Standard Deviation 2-million $({\sigma} = 2)$
- Hypothesis test to check whether the average sales value in the population is at least 8-million

```{r 'B14D07', comment="", echo=FALSE, results='asis'}
f_getDef("Hypothesis-1T-Upper-Tail") #dddd
```

\textcolor{orange}{Caution:} While importing data, for Mac users, probably it will be easier to import CSV file. However, I am not a Mac user so cannot comment on this.

### Data {.unlisted .unnumbered}

```{r 'B14-Data'}
# #Import the Data and assign to a temporary variable for ease of use
xxWSES <- f_getRDS(xxWSES)
bb <- xxWSES
str(bb)
```

### Rename Headers {.unlisted .unnumbered}

```{r 'B14-Rename'}
# #List Column Headers
names(bb)
#
# #Rename Headers
bb_headers <- c("SN" , "RS" , "SO" , "PDT" , "INT" , "RG" , "RS1" , "PM" , "SVM" , "PP" , "JB" , "LCC")
names(bb) <- bb_headers
#
# #Verification
names(bb)
#
```

### Conversion to Factor {.unlisted .unnumbered .tabset .tabset-fade}

- From the case study, it can be seen that multiple columns are categorical (factor) or ordinal (ordered factor)

- \textcolor{pink}{Question:} What is the importance of having this kind of order factor over simple factor
  - Here order is also important. Also in future, ordered factors will be needed for some analysis
  - (Aside) Refer [Scales of Measurement](#scales-c01 "c01")
    - Simple factor (nominal) can provide only Mode whereas Ordered factor (ordinal) can provide Median also. Rank based statistical models can be applied on the ordinal data.
- \textcolor{pink}{Question:} If 'RS' is already integer 0 & 1, then why convert it to factor
  - While the data shows them as 0 & 1 but actually they are NOT integers
  - If we show male and female as 0 & 1, these are still categorical
- \textcolor{pink}{Question:} Why LCC is NOT ordinal (Aside)
  - Unknown "ForLater"

#### Data {.unlisted .unnumbered}

```{r 'B14-Factors'}
# #"Reporting Status i.e. RS" Converting "character" to "factor" and Label them
bb$RS <- factor(bb$RS, levels = c("Lost", "Won"), labels = c("0", "1"))
#
# #"Sales Outcome i.e. SO" Converting "numeric" to "factor" 
bb$SO <- factor(bb$SO)
#
# #"Product Vertical i.e. PDT" Ordinal
# #What are the unique values in this column
unique(bb$PDT)
#
# #Converting "character" to "Ordered factor"
# #Note: If level order is not provided, by default, alphabatical ordering will be assigned.
levels(factor(bb$PDT, ordered = TRUE))
#
# #Provide ordering of factor levels in Ascending Order.
bb$PDT <- factor(bb$PDT, ordered = TRUE, 
      levels = c("GTMSys", "Procsys", "LearnSys", "Finsys", "Lifesys", "Logissys", "ContactSys"))
#
# #"Industry i.e. INT" Ordinal
bb$INT <- factor(bb$INT, ordered = TRUE, 
      levels = c("Capital Markets", "Banks", "Defense", "Consumer goods", "Others", "Security", 
        "Energy", "Insurance", "Airline", "Finance", "Infrastructure", "Mobility", "Other Govt.", 
        "Govt.", "Telecom equipments", "Health", "Clinical research", "Agriculture"))
#
# #"Region i.e. RG" Ordinal
bb$RG <- factor(bb$RG, ordered = TRUE, levels = c("UK", "Other Europe", "Americas", "Africa",
                                                "India", "Japan", "Singapore", "Spain", "Canada"))
#
# #"Leads Conversion Class i.e. LCC" Ordinal, However we are going with Nominal here.
bb$LCC <- factor(bb$LCC, levels = c("E", "V", "F", "L"), labels = c(1, 2, 3, 4))
```

#### Structure after Conversion {.unlisted .unnumbered}

```{r 'B14-SaveData', include=FALSE, eval=FALSE}
xyWSES <- bb
f_setRDS(xyWSES)
```

```{r 'B14-WorkingData'}
str(bb)
```

#### factor() {.unlisted .unnumbered}

- \textcolor{pink}{factor()}
  - If level order is not provided, by default, alphabatical ordering will be assigned.
  - levels are the input, labels are the output in the factor() function. 
  - A factor has only a level attribute, which is set by the labels argument in the factor() function.
  - different levels are coded as ("E", "V", "F", "L")
    - for which you want the levels to be labeled as c(1, 2, 3, 4).
    - The factor function will look for the values ("E", "V", "F", "L") convert them to numerical factor classes and add the label values to the 'level' attribute of the factor. 
    - This attribute is used to convert the internal numerical values to the correct labels. 
    - Hoever, there is no 'label' attribute. 

### Conversion to Numeric 

```{r 'B14-ChangeType', eval=FALSE}
# #If there are "character" columns which should be "numeric"
bb$RS1 <- as.numeric(bb$RS1)
bb$PP <- as.numeric(bb$PP)
bb$JB <- as.numeric(bb$JB)
# #Equivalent
bb <- bb %>% mutate(across(c(RS1, PP, JB), as.numeric))
```

## WSES: Analysis

### Q1

Assume average sales of 8-million dollars and population standard deviation to be 2-million dollars. Check whether the average sales value in the population is at least 8 million dollars.

```{r 'B14D01', comment="", echo=FALSE, results='asis'}
f_getDef("Hypothesis-1T-Upper-Tail")
```

- Mean of "Sales Value in Million i.e. SVM"
  - ${\overline{x}} = 8.0442$
    - `mean(bb$SVM)` \textcolor{pink}{$\#\mathcal{R}$}
- $n = 1000, {\mu} = 8, {\sigma} = 2$
- $z = \frac{\overline{x} - {\mu}_0}{{\sigma}/\sqrt{n}} = 0.6988$
  - `{8.0442 - 8} / {2 / sqrt(1000)}` \textcolor{pink}{$\#\mathcal{R}$}
  - `{mean(bb$SVM) - 8} / {2 / sqrt(1000)}` \textcolor{pink}{$\#\mathcal{R}$}
- ${}^U\!P_{z = 0.6988} = 0.2423$
  - `pnorm(q = 0.6988, lower.tail = FALSE)` \textcolor{pink}{$\#\mathcal{R}$} 
  - `1 - pnorm(q = 0.6988, lower.tail = TRUE)` \textcolor{pink}{$\#\mathcal{R}$} 
  - `1 - pnorm(q = 0.6988)` \textcolor{pink}{$\#\mathcal{R}$} 
  - `pnorm(q = -0.6988)` \textcolor{pink}{$\#\mathcal{R}$} 
  - \textcolor{orange}{Caution:} By default, `pnorm()` provides the probability to the left of z-value
- Compare with ${\alpha} = 0.05$
  - ${}^U\!P_{(z)} > {\alpha} \to {H_0}$ cannot be rejected 
  - The sample results do not provide sufficient evidence to conclude that the average sales is 'at least' 8-million 
  
### Q2

If the population standard deviation is unknown, evaluate the same hypothesis again.

- $t = \frac{\overline{x} - {\mu}_0}{{s}/\sqrt{n}} = 0.7049$
  - `{mean(bb$SVM) - 8} / {sd(bb$SVM) / sqrt(1000)}` \textcolor{pink}{$\#\mathcal{R}$}
- ${}^U\!P_{t = 0.7049} = 0.2405$
  - `pt(q = 0.7049, df = nrow(bb) - 1, lower.tail = FALSE)` \textcolor{pink}{$\#\mathcal{R}$} 
- \textcolor{pink}{t.test()}
  - `t.test(bb$SVM, mu = 8, alternative = "greater")` \textcolor{pink}{$\#\mathcal{R}$} 
- Compare with ${\alpha} = 0.05$
  - ${}^U\!P_{(t)} > {\alpha} \to {H_0}$ cannot be rejected 
  - The sample results do not provide sufficient evidence to conclude that the average sales is 'at least' 8-million (same as earlier)
- \textcolor{pink}{Question:} "alternative hypothesis: true mean is greater than 8" What is the meaning of this line in the output of t.test
  - We provided this information.
  - (Aside) This line is providing the Alternate Hypothesis for reference. ${\mu}_0 = 8$ and we are performing an upper tail test thus the Alternate Hypothesis is "true mean is greater than 8"


### Q3 {.tabset .tabset-fade}

Check whether the proportion of leads won by WSES is more than 50%.

```{r 'B14D04', comment="", echo=FALSE, results='asis'}
f_getDef("H-1s-p-Upper")
```

- Count of Success $({x})$ is Winning leads in the "Sales Outcome i.e. SO"
- ${p}_0 = 0.50$
  - \@ref(eq:se-1s-p) ${\sigma}_{\overline{p}} = \sqrt{\frac{{p}_0 (1 - {p}_0)}{n}} = 0.0158$
    - `sqrt(0.50 * {1 - 0.50} / 1000)` \textcolor{pink}{$\#\mathcal{R}$}
- $\{n = 1000, x = 481\} \to {\overline{p}} = {n}/{x} = 0.481$ 
- \@ref(eq:z-1s-p) $z = \frac{{\overline{p}} - {p}_0}{{\sigma}_{\overline{p}}} = -1.2016$
  - `{0.481 - 0.50}/{sqrt(0.50 * {1 - 0.50} / 1000)}` \textcolor{pink}{$\#\mathcal{R}$} 
- ${}^U\!P_{z = -1.2016} = 0.8852$
  - `pnorm(q = -1.2016, lower.tail = FALSE)` \textcolor{pink}{$\#\mathcal{R}$} 
  - `1 - pnorm(q = -1.2016)` \textcolor{pink}{$\#\mathcal{R}$} 
- Compare with ${\alpha} = 0.05$
  - ${}^U\!P_{(z)} > {\alpha} \to {H_0}$ cannot be rejected 
  - The sample results do not provide sufficient evidence to conclude that the company wins 'at least' 50% leads

#### Code {.unlisted .unnumbered}

```{r 'B14-Proportions'}
# #Proportions
bb %>% group_by(SO) %>% summarise(PCT = n() / nrow(.))
#
pnorm(q = -1.2016, lower.tail = FALSE)
```

#### Percentage {.unlisted .unnumbered}

```{r 'B14-GroupPercentage'}
# #Grouped Percentages
# #table() gives a count
table(bb$SO)
#
# #prop.table() can work only with numbers so it needs table()
prop.table(table(bb$SO))
#
# #Similar
bb %>% group_by(SO) %>% summarise(N = n()) %>% mutate(PCT = N / sum(N))
bb %>% group_by(SO) %>% summarise(PCT = n() / nrow(.))
```

### Q4 {.tabset .tabset-fade}

Check whether the probability of winning a sales lead for the product "learnsys" is more than that of "Finsys". 

```{r 'B14D05', comment="", echo=FALSE, results='asis'}
f_getDef("H-2s-p-Upper") 
```

- Count of Success $({x})$ is Winning leads in the "Sales Outcome i.e. SO"
- (1: learnsys) $\{{n}_1 = 55 + 71 = 126, {x}_1 = 71\} \to {\overline{p}}_1 = {n}_1/{x}_1 = 0.563$
- (2: Finsys) $\{{n}_2 = 83 + 34 = 117, {x}_2 = 34\} \to {\overline{p}}_2 = {n}_2/{x}_2 = 0.29$
- ${}^U\!P_{z} < {\alpha} \to {H_0}$ is rejected i.e. the proportions are different
  - We can conclude that the "learnsys" performs better than "Finsys"


- \textcolor{pink}{Question:} When we have filtered out the data, why the table shows 0 values
  - We can filter them out, however these are in memory
  - (Aside) Factor levels are not dropped, by default, when you filter them. Use factor() again to drop the unused levels. 

#### Test {.unlisted .unnumbered}

```{r 'B14-TestProportion'}
# #Data | Subset | Filter | Update Factor levels
ii <- bb %>% select(PDT, SO, SVM) %>% 
  filter(PDT %in% c("LearnSys", "Finsys")) %>% mutate(across(PDT, factor))
str(ii)
#
# #Count
table(ii$PDT, ii$SO)
#
# #Proportion Table
round(prop.table(table(ii$PDT, ii$SO), margin = 1), 3)
#
prop.test(x = c(71, 34), n = c(126, 117), alternative = "greater")
```

#### filter() {.unlisted .unnumbered}

```{r 'B14-Filter'}
# #Subset the dataset
ii <- data.frame(PDT = bb$PDT, SO = bb$SO, SVM = bb$SVM)
# #Subset only for required type of rows #243 Observations
jj <-  subset(ii, PDT == "LearnSys" | PDT == "Finsys")
#
# #subset() is discouraged. Alternatives are given below
kk <- ii[ii$PDT %in% c("LearnSys", "Finsys"), ]
ll <- ii[which(ii$PDT %in% c("LearnSys", "Finsys")), ]
#
mm <- bb %>% select(PDT, SO, SVM) %>% filter(PDT == "LearnSys" | PDT == "Finsys")
nn <- bb %>% select(PDT, SO, SVM) %>% filter(PDT %in% c("LearnSys", "Finsys"))
#
stopifnot(all(identical(jj, kk), identical(jj, ll), 
              identical(as_tibble(jj), mm), identical(mm, nn)))
str(nn)
```

#### prop.table() {.unlisted .unnumbered}

```{r 'B14-MoreProportion'}
ii <- bb %>% select(PDT, SO, SVM) %>% 
  filter(PDT %in% c("LearnSys", "Finsys")) %>% mutate(across(PDT, factor))
str(ii)
#
# #Proportion Table: margin gives the margin to split by i.e. 
# #1 means rowwise sum, 2 means columnwise
round(prop.table(table(ii$PDT, ii$SO), margin = 1), 3)
round(prop.table(table(ii$PDT, ii$SO), margin = 2), 3)
#
# #Similar
ii %>% select(PDT, SO) %>% 
  count(PDT, SO) %>% pivot_wider(names_from = SO, values_from = n) %>% 
  mutate(SUM = rowSums(across(where(is.numeric)))) %>% 
  mutate(across(where(is.numeric), ~ round(. * 100 /SUM, 1))) 
```


### Q5

Check whether the average sales value of "learnsys" projects is higher than that of "Finsys" projects. (${\alpha} = 0.05$)

```{r 'B14D06', comment="", echo=FALSE, results='asis'}
f_getDef("H-2s-Upper")
```

- t-test for difference of means can be applied only if the variances are same.
  - Location of two distributions can be compared only when their spread is similar.
- ${}^U\!P_{t} > {\alpha} \to {H_0}$ cannot be rejected 
  - The sample results do not provide sufficient evidence to conclude that the "learnsys" has higher average sales than "Finsys"

- \textcolor{pink}{Question:} What is 'SVM ~ PDT'
  - It is the formula notation for t-test (in R) in the form of 'Continuous ~ Categorical'

"ForLater"

- \textcolor{pink}{Question:} How to decide whether to keep the Lost bids or exclude them
  - Including lost bids: $\text{(DOF)} = 241, t = 0.93503, P_{(t)} = 0.1754 \to {H_0}$ cannot be rejected
  - Excluding lost bids: $\text{(DOF)} = 103, t = 0.62152, P_{(t)} = 0.2678 \to {H_0}$ cannot be rejected
  - Thus, no change in Hypothesis results but which which process should be utilised 
  - Similar, question can be raised for Q6 i.e. should be consider profit of those bids which we lost

```{r 'B14-Q5t2s'}
str(ii)
ii_var <- var.test(SVM ~ PDT, data = ii)
if(ii_var$p.value > 0.05) {
  t.test(formula = SVM ~ PDT, data = ii, alternative = "greater", var.equal = TRUE)
} else {
  cat(paste0("Problem: Difference of means can be tested only if the variances are same.\n"))
}
```

```{r 'B14-NoLost'}
jj <- ii %>% filter(SO == "1")
jj_var <- var.test(SVM ~ PDT, data = jj)
if(jj_var$p.value > 0.05) {
  t.test(formula = SVM ~ PDT, data = jj, alternative = "greater", var.equal = TRUE)
} else {
  cat(paste0("Problem: Difference of means can be tested only if the variances are same.\n"))
}
```

### Q6

Check whether there is a difference in the average profit across the geographical locations: United Kingdom, India and the Americas. 

- We need to conduct ANOVA because there are more than 2 levels we are checking

- \textcolor{pink}{aov()}
  - Total Variance = Between or MSTR + Within or MSE
    - Sum Sq provides SSTR & SSE
    - Mean Sq provides MSTR (Between) & MSE (Within)
  - First Line (Column): $\text{DOF}_{(k-1)} = 2, \text{SSTR} = 297, \text{MSTR} = 148.7$
  - Residuals (Within) : $\text{DOF}_{(n-k)} = 689, \text{SSE} = 68075, \text{MSE} = 98.8$
  - \@ref(eq:f-anv) $F = \frac{\text{MSTR}}{\text{MSE}} = 1.5$
  - ${}^U\!P_{F = 1.5} = 0.2238$
    - `pf(q = 1.5, df1 = 2, df2 = 689, lower.tail = FALSE)` \textcolor{pink}{$\#\mathcal{R}$} 
  - Compare with ${\alpha} = 0.05$
    - ${}^U\!P_{(F)} > {\alpha} \to {H_0}$ cannot be rejected 
    - The sample results do not provide sufficient evidence to conclude that the average profit differs across the 3 geographical locations. 

- \textcolor{pink}{Question:} Sample size of these 3 groups are different (UK 553, Americas 104, India 35). Would this impact our analysis
  - If the sample size are similar, then the power will be more but otherwise ANOVA is not very sensitive to unequal sample sizes. We can safely use it.

- \textcolor{orange}{Warning:} 
  - "Warning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)"
  - remove 'type' option from aov()
    
```{r 'B14-Q6anova'}
ii <- bb %>% filter(RG %in% c("UK", "India", "Americas")) %>% select(RG, PP, SO)
str(ii)
#
# #ANOVA
ii_aov <- aov(formula = PP ~ RG, data = ii)
#
# #
model.tables(ii_aov, type = "means")
#
# #Summary
summary(ii_aov)
```

```{r 'B14-q6noLost'}
jj <- ii %>% filter(SO == "1")
str(jj)
#
# #ANOVA
jj_aov <- aov(formula = PP ~ RG, data = jj)
#
# #
model.tables(jj_aov, type = "means")
#
# #Summary
summary(jj_aov)
```

### Q7

Check whether the sales conversions are different for different geographical locations. 

- Both (Location and Sales Conversions) are categorical variables, So ChiSq Test is required
- $P_{\chi^2} < {\alpha} \to {H_0}$ is rejected i.e. proportions are different
  - It can be claimed that there is an association between these variables.
  - We can conclude that the sales conversions are different for different geographical locations
  


- \textcolor{orange}{Warning:} 
  - "Warning in chisq.test() Chi-squared approximation may be incorrect: 
  - Some of observed frequencies in the Table are too few e.g. Canada

```{r 'B14-Q7chisq'}
ii <- bb %>% select(RG, SO)
str(ii)
#
round(prop.table(table(ii$RG, ii$SO), margin = 1), 3)
#
# #Chi-Sq Test
tryCatch(chisq.test(table(ii$RG, ii$SO)), 
         warning = function(w) {
           print(paste0(w))
           suppressWarnings(chisq.test(table(ii$RG, ii$SO)))
           })
```

### Q8

- Check whether the sales conversions depend on the sales value. Check this claim by making 3 groups of Sales Value: <6-million, [6-8], >8-million dollar 

- Both are categorical variables, So ChiSq Test is required
- $P_{\chi^2} > {\alpha} \to {H_0}$ cannot be rejected. 
  - It cannot be claimed that there is an association between these variables.
  - The sample results do not provide sufficient evidence to conclude that the sales conversions depend on the sales value. 
  

  
```{r 'B14-Q8chisq'}
ii <- bb %>% select(SO, SVM)
#
# #Create 3 Groups with middle group inclusive of both 6 & 8 
ii$RSVM <- cut(ii$SVM, breaks = c(0, 5.9999, 8, 15), labels = 1:3)
#
summary(ii)
#
table(ii$RSVM, ii$SO)
#
# #Chi-Sq Test
chisq.test(table(ii$RSVM, ii$SO))
```


## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B14-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ee, hh, ii, jj, kk, ll, mm, nn, oo, rr, vv, xx, yy, zz, bb_headers, ii_aov, 
          ii_var, jj_aov, jj_var, xxWSES)
```

```{r 'B14-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
