# Decision Tree Algorithm (B32, Feb-13) {#b32}

```{r 'B32', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- "Decision Tree Algorithm"

## Packages

```{r 'B32-Installations', eval=FALSE}
if(FALSE){# #WARNING: Installation may take some time.
  install.packages("rattle", dependencies = TRUE)
  install.packages("janitor", dependencies = TRUE)
  install.packages("randomForest", dependencies = TRUE)
}
```

## Car Dekho - Data

- [Import Data CarDekho - B26](#set-cardekho-b26 "b26")

```{r 'B32-GetCarDekho', ref.label=c('B26-GetCarDekho', 'B26-PrepCar', 'B31-Dummies-Car')}
# #xxB26CarDekho, aa, bb, xsyw, xw,xsw, zfw, xnw, znw, 
# #train_xfw, test_xfw, train_xfw_ii, test_xfw_ii
```

```{r 'B32-GetCarDekhoKnit', include=FALSE, eval=FALSE}
xxB26CarDekho <- f_getRDS(xxB26CarDekho)
aa <- xxB26CarDekho
bb <- aa %>% 
  separate(name, c("brand", NA), sep = " ", remove = FALSE, extra = "drop") %>% 
  filter(fuel != "Electric") %>% 
  #mutate(across(where(is.character), factor)) %>% 
  mutate(across(fuel, factor, levels = c("Diesel", "Petrol", "CNG", "LPG"))) %>% 
  mutate(across(transmission, factor, levels = c("Manual", "Automatic"), 
                labels = c("Manual", "Auto"))) %>% 
  mutate(across(owner, factor, 
levels = c("First Owner", "Second Owner", "Third Owner", "Fourth & Above Owner", "Test Drive Car"), 
labels = c("I", "II", "III", "More", "Test"))) %>% 
  mutate(across(seller_type, factor, levels = c("Individual", "Dealer", "Trustmark Dealer"), 
                labels = c("Indiv", "Dealer", "mDealer"))) %>% 
  rename(price = selling_price, km = km_driven, 
         s = seller_type, o = owner, t = transmission, f = fuel) %>% 
  mutate(age = 2022 - year) %>% 
  select(-c(year, name, brand))
# 
xfw <- bb
zfw <- xfw %>% mutate(across(where(is.numeric), ~ as.vector(scale(.)))) 
xnw <- xfw %>% select(where(is.numeric))
znw <- zfw %>% select(where(is.numeric))
#
# #Dummy | Drop First Level i.e. Reference | Drop Selected Columns i.e. Original |
dum_xfw <- xfw %>% dummy_cols(.data = ., 
                  select_columns = c("f", "s", "t", "o"), 
                  remove_first_dummy = TRUE, remove_selected_columns = TRUE)
#
# #Partition Data
set.seed(3)
idx_xfw <- sample.int(n = nrow(dum_xfw), size = floor(0.8 * nrow(dum_xfw)), replace = FALSE)
train_xfw <- dum_xfw[idx_xfw, ]
test_xfw  <- dum_xfw[-idx_xfw, ]
#
# #Decision Trees: Convert Dummy Variables to Factor Variables of two levels "0", "1"
train_xfw_ii <- train_xfw %>% mutate(across(starts_with(c("s_", "f_", "t_", "o_")), factor))
test_xfw_ii  <- test_xfw  %>% mutate(across(starts_with(c("s_", "f_", "t_", "o_")), factor))
```

```{r 'B32-PrintTree', include=FALSE, eval=FALSE}
# #Printing Tree
ii <- as.party(hh)
length(ii)
width(ii)
depth(ii)
ii
```

## Backticks

- `` `Header Names containing Spaces or Symbols are referred by surrounding them in Backticks` ``
  - As shown in the above line
  - Backtick can be found on the Tilde "~" Key, just below the Escape Key.
  - \textcolor{orange}{Caution:} R sometimes can handle special symbols within single quotes and sometimes it fails. 
    - Thus it is recommended to use backticks to handle special symbols
    - Mostly it is found when Column Names contain Spaces

```{r 'B32-Backticks'}
# #There is NO difference between Double Quotes (" ") and Single Quotes (' ')
identical("a", 'a')
#
# #However Backticks (` `) may behave differently than Single Quotes (' ')
if(FALSE) identical(`a`, 'a') #Error 
#
# #Backticks are needed to Create /Manipulate Header Names with special symbols 
# #Column 1 needed to be surrounded with Backticks whereas Column 2 does not require this
bb <- tibble(`header'has'single_quotes` = 1:3, header_no_single_quote = 4:6)
str(bb)
#
# #Convert Columns from integer to character by using Column Names
bb$header_no_single_quote   <- as.character(bb$header_no_single_quote)
#bb$header'has'single_quotes   <- as.character(bb$`header'has'single_quotes`)  #Error
#bb$'header'has'single_quotes' <- as.character(bb$`header'has'single_quotes`)  #Error
# #Works
bb$`header'has'single_quotes`  <- as.character(bb$`header'has'single_quotes`)
#
str(bb)
```

## Model Parameters

- \textcolor{pink}{modelLookup()}
  - It provides information about the parameters avaialble for the given model and their applicability on Regression or Classification problem

```{r 'B32-Lookup-Model'}
# #modelLookup() for information about models and packages that are accessible via train()
modelLookup('rpart')
```

## Build Tree

- Plots have been generated in previous lecture - "ForLater" Link
- "dummy coding" is also known as "one-hot encoding"
- We can use complexity parameter $C_p \in [0, 1]$ for pruning
  - It decides the minimum information gain. Any branch having lower gain than that will be pruned 
  - High value of $C_p$ will result in small tree
  - Pruning also helps in avoiding the problem of outliers

```{r 'B32-Tree-Car'}
# #rpart() for Tree Model
mod_tree <- rpart(price ~ ., data = train_xfw_ii, method = 'anova')
#
# #Very Long Output 
#summary(mod_tree)
hh <- mod_tree
```

```{r 'B32-PrintTree-Car', ref.label=c('B32-PrintTree')}
#
```

## Parameter Tuning 

- Limitation of Train and Test Concept
  - When we are using 80% of data for Training purpose, we are not able to utilise the information in the other 20% for model building
  - This might lead to bias in the model because we have not considered one portion of data
- k-fold Cross-validation helps in utilising all the information available
  - Refer [Cross-validation B28](#cross-b28 "b28")

```{r 'B32D01', comment="", echo=FALSE, results='asis'}
f_getDef("Cross-Validation") #dddd
```

- \textcolor{pink}{Question:} Which one to choose from the Simple Two-fold, k-fold CV and repeated CV
  - Depends upon the available computational resources (time, memory, cost etc.)

- It is possible for each model (repeated CV) to run with different values of $C_p$
  - For each $C_p$ of each model we can calculate RMSE
  - For each value of $C_p$ we can calculate Average RMSE across all Models
  - The $C_p$ value having lowest average RMSE across all models would be the optimum one.
  - This process for identification of optimum $C_p$ is \textcolor{pink}{parameter tuning}

- \textcolor{pink}{Question:} shoule we do this process only for identification of $C_p$
  - In general, Cross-validation provides better result
  - Some people prefer to split the dataset and then on the training set do the cross-validation
  - However, cross-validation on complete dataset can also be done 

- If we find that we are unable to improve accuracy between two-fold and k-fold, we can do the k-fold on complete data.
  - However, in that case, it would not be comparable models because base model would be trained on only 80% of data.

## Predict

- Prediction Accuracy is only 35.9% 

```{r 'B32-Predict-Car'}
# #Model Validation
#res_tree <- predict(mod_tree, test_xfw_ii, type  = "vector") 
res_tree <- test_xfw_ii %>% 
  mutate(CalY = predict(mod_tree, ., type = "vector"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
ii <- res_tree
summary(ii$Y_Yc)
#
# #Correlation 
cor(ii$price, ii$CalY)
#
# #RMSE: Root Mean Squared Error
sqrt(mean((ii$Y_Yc)^2))
#
# #MAE: Mean Absolute Error (MAE)
mean(abs(ii$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(ii$MAPE))
#
# #Accuracy 
1 - mean(abs(ii$MAPE))
```

## Cleaning Names

- A syntactically valid name consists of letters, numbers and the dot or underline characters and starts with a letter or the dot not followed by a number.
- 'janitor' or 'dplyr' packages can be used to rename the headers to R standards

```{r 'B32-Rename'}
# #Rename All Column Headers to proper names
bb <- tibble("A_Underscore" = 1, "B.Dot" = 2, "C Space" = 3, "D-Dash" = 4, `E'apostrophe` = 5) #'
ii <- janitor::clean_names(bb)
jj <- bb %>% dplyr::rename_with(make.names) %>% 
  rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) 
#
names(bb)
names(ii)
names(jj)
```

## Setup Parallel

- Allow Parallel

```{r 'B32-ModelControl'}
cv <- trainControl(method = "repeatedcv", number = 10, repeats = 5, allowParallel = TRUE)
```


## Crossvalidation

- \textcolor{orange}{Warning:} 
  - "Warning in nominalTrainWorkflow : There were missing values in resampled performance measures."
  - If this is regression, the most likely case is that the tree did not find a good split and used the average of the outcome as the predictor. It is fine but you cannot calculate $R^2$ since the variance of the predictions is zero. 
  - For now, assume that the warning is not importnat - "ForLater"

- Accuracy improved to 42.5% (from 35.9%) with cp = 0.008528435

```{r 'B32-CV-Car'}
# #train() tuneLength decides the granularity in the tuning parameter grid
mod_cv <- suppressWarnings(train(price ~ ., data = train_xfw_ii, method = 'rpart', 
                trControl = cv, tuneLength = 10))
#mod_cv
#
# #Best Tuning Cp value
mod_cv$bestTune
```


```{r 'B32-Predict-cv-Car'}
# #Model Validation
# #Class of Both Models are different. rpart() require "vector" but "raw" is used with train()
class(mod_tree)
class(mod_cv)
#
#res_tree <- predict(mod_cv, test_xfw_ii, type  = "raw") 
res_cv <- test_xfw_ii %>% 
  mutate(CalY = predict(mod_cv, ., type = "raw"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
ii <- res_cv
summary(ii$Y_Yc)
#
# #RMSE: Root Mean Squared Error
sqrt(mean((ii$Y_Yc)^2))
#
# #MAE: Mean Absolute Error (MAE)
mean(abs(ii$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(ii$MAPE))
#
# #Accuracy 
1 - mean(abs(ii$MAPE))
```

```{r 'B32-CP-Car'}
# #rpart() for Tree Model using Tuned cp obtained from Cross-validation
# #Needed to plot this CV model 
mod_tree_cp <- rpart(price ~ ., data = train_xfw_ii, method = 'anova', cp = 0.008528435)
#
# #Very Long Output 
#summary(mod_tree_cp)
```

```{r 'B32-Tree-rpart', include=FALSE, eval=FALSE}
# #IN: cap_hh, ttl_hh, loc_png, hh <- mod_tree
#
if(!file.exists(loc_png)) {
  png(filename = loc_png) 
  #dev.control('enable') 
  rpart.plot(hh, extra = 'auto')
  title(main = ttl_hh, line = 2, adj = 0)
  title(sub = cap_hh, line = 4, adj = 1)
  B31 <- recordPlot()
  dev.off()
  assign(cap_hh, B31)
  rm(B31)
}
```


```{r 'B32-Tree-rpart-Set', include=FALSE}
hh <- mod_tree_cp
#
cap_hh <- "B32P01"
ttl_hh <- "CarDekho: Tree by Crossvalidation"
loc_png <- paste0(.z$PX, "B32P01", "-Tree-cv", ".png")
```

```{r 'B32P01-Save', include=FALSE, ref.label=c('B32-Tree-rpart')}
#
```

```{r 'B32P01', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B32P01", "-Tree-cv", ".png"))
```


```{r 'B32P01-A', echo=FALSE, ref.label=c('B31P08', 'B32P01'), fig.cap="(B31P08, B32P01) CarDekho: Two-part vs 10-part CV Tree"}
#
```

## KC House - Data  {.tabset .tabset-fade}

- [Import Data KC House - B30](#set-kc-b30 "b30")
- Note: More columns have been included in Decision Trees, compared to Linear Regression, because no checks have been done on normality or multicollinearity (VIF)

### Preprocessing {.unlisted .unnumbered}

```{r 'B32-GetKC-Tree'}
# #Load Data: KC House
xxB30KC <- f_getRDS(xxB30KC)
# #Drop NA | Get Age | Dummy | Rename | Filter | Factor | Relevel Most Frequent Reference | 
# #Drop | Relocate |
xfw <- xxB30KC %>% 
  drop_na() %>% 
  #mutate(across(date, as_date)) %>% 
  mutate(sold = year(date), age = sold - yr_built) %>% 
  mutate(iRenew = ifelse(yr_renovated == 0, 0, 1)) %>% 
  rename(beds = bedrooms, baths = bathrooms, sqAbove = sqft_above, sqLot = sqft_lot, 
         iWater = waterfront, iView = view) %>% 
  filter(beds != 33) %>% 
  mutate(across(c(beds, baths, floors, iWater, iView, condition, grade, iRenew), factor)) %>% 
  mutate(across(c(zipcode), factor)) %>% 
  mutate(across(beds, relevel, ref = "3")) %>% 
  mutate(across(baths, relevel, ref = "2")) %>% 
  mutate(across(floors, relevel, ref = "1")) %>% 
  mutate(across(condition, relevel, ref = "3")) %>% 
  mutate(across(grade, relevel, ref = "7")) %>% 
  mutate(across(zipcode, relevel, ref = "98103")) %>% 
  select(-c(id, lat, long, date, sold, yr_renovated, yr_built, 
            sqft_living, sqft_living15, sqft_lot15)) %>% 
  select(-c(zipcode)) %>% 
  relocate(price)
```

```{r 'B32-Dummies-KC'}
# #Partition Data
set.seed(3)
# #Create Dummies | Replaced All NA in original data so no replacement in dummy columns |
dum_xfw <- dummy_cols(xfw, remove_first_dummy = TRUE, remove_selected_columns = TRUE) 
idx_xsyw <- sample.int(n = nrow(dum_xfw), size = floor(0.8 * nrow(dum_xfw)), replace = FALSE)
train_xfw <- dum_xfw[idx_xsyw, ] 
test_xfw  <- dum_xfw[-idx_xsyw, ]
```

```{r 'B32-TreeFact-KC'}
# #Decision Trees: Convert Dummy Variables to Factor Variables of two levels "0", "1"
train_xfw_ii <- train_xfw %>% mutate(across(starts_with(c(
  "beds_", "baths_", "floors_", "iWater_", "iView_", "condition_", "grade_", "iRenew_")), factor))
test_xfw_ii <- test_xfw %>% mutate(across(starts_with(c(
  "beds_", "baths_", "floors_", "iWater_", "iView_", "condition_", "grade_", "iRenew_")), factor))
```

### Structure {.unlisted .unnumbered}

```{r 'B32-Structure-KC'}
str(train_xfw_ii)
```

### Summary {.unlisted .unnumbered}

```{r 'B32-Summary-KC'}
#summary(train_xfw_ii)
train_xfw_ii %>% select(where(is.numeric)) %>% summary()
#
train_xfw_ii %>% select(!where(is.numeric)) 
```


## Decision Tree 

- Prediction Accuracy is only 63.4%

```{r 'B32-Tree-KC'}
# #Decision Tree Model
mod_tree <- rpart(price ~ ., data = train_xfw_ii, method = 'anova')
#
# #Very Long Output 
#summary(mod_tree)
hh <- mod_tree
```

```{r 'B32-PrintTree-KC', ref.label=c('B32-PrintTree')}
#
```

```{r 'B32-Tree-rpart-Set-KC', include=FALSE}
hh <- mod_tree
#
cap_hh <- "B32P02"
ttl_hh <- "KC: Tree"
loc_png <- paste0(.z$PX, "B32P02", "-Tree-KC-Rpart", ".png")
```

```{r 'B32P02-Save', include=FALSE, ref.label=c('B32-Tree-rpart')}
#
```

```{r 'B32P02', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B32P02", "-Tree-KC-Rpart", ".png")) #iiii
```

```{r 'B32-Predict-KC'}
# #Model Validation
#res_tree <- predict(mod_tree, test_xfw_ii, type  = "vector") 
res_tree <- test_xfw_ii %>% 
  mutate(CalY = predict(mod_tree, ., type = "vector"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
ii <- res_tree
summary(ii$Y_Yc)
#
# #Correlation 
cor(ii$price, ii$CalY)
#
# #RMSE: Root Mean Squared Error
sqrt(mean((ii$Y_Yc)^2))
#
# #MAE: Mean Absolute Error (MAE)
mean(abs(ii$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(ii$MAPE))
#
# #Accuracy 
1 - mean(abs(ii$MAPE))
```

## Get Cp

```{r 'B32-CalCp-KC'}
# #Calculate cp
printcp(mod_tree)
```

```{r 'B32-Cp-Set-KC', include=FALSE}
hh <- mod_tree
#
cap_hh <- "B32P04"
ttl_hh <- "KC: Plot Cp"
loc_png <- paste0(.z$PX, "B32P04", "-KC-CP", ".png")
```

```{r 'B32-Cp-KC', include=FALSE, eval=FALSE}
# #IN: cap_hh, ttl_hh, loc_png, hh <- mod_tree
#
if(!file.exists(loc_png)) {
  png(filename = loc_png) 
  #dev.control('enable') 
  plotcp(mod_tree)
  title(main = ttl_hh, line = 2, adj = 0)
  title(sub = cap_hh, line = 4, adj = 1)
  B31 <- recordPlot()
  dev.off()
  assign(cap_hh, B31)
  rm(B31)
}
```

```{r 'B32P04-Save', include=FALSE, ref.label=c('B32-Cp-KC')}
#
```

```{r 'B32P04', echo=FALSE, fig.cap="(B32P04) KC: Plot Cp"}
knitr::include_graphics(paste0(.z$PX, "B32P04", "-KC-CP", ".png")) #iiii
```

## Pruning by Cp

- Prediction Accuracy is 61% (reduced from 63.4%)

```{r 'B32-Pruned-KC'}
# #Decision Tree Model with pruning
mod_prune <- prune.rpart(mod_tree, cp = 0.028)
#
# #Very Long Output 
#summary(mod_prune)
hh <- mod_prune
```

```{r 'B32-PrintTree-KC-Pruned', include=FALSE, eval=FALSE, ref.label=c('B32-PrintTree')}
#
```

```{r 'B32-Predict-Prune-KC'}
# #Model Validation
#res_prune <- predict(mod_prune, test_xfw_ii, type  = "vector") 
res_prune <- test_xfw_ii %>% 
  mutate(CalY = predict(mod_prune, ., type = "vector"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
ii <- res_prune
summary(ii$Y_Yc)
#
# #Correlation 
cor(ii$price, ii$CalY)
#
# #RMSE: Root Mean Squared Error
sqrt(mean((ii$Y_Yc)^2))
#
# #MAE: Mean Absolute Error (MAE)
mean(abs(ii$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(ii$MAPE))
#
# #Accuracy 
1 - mean(abs(ii$MAPE))
```

## Crossvalidation

- Accuracy is 63.4% (similar to original) with cp = 0.01105875	

```{r 'B32-ModelControl-KC'}
cv <- trainControl(method = "repeatedcv", number = 10, repeats = 5, allowParallel = TRUE)
```

```{r 'B32-CV-KC'}
# #train() tuneLength decides the granularity in the tuning parameter grid
mod_cv <- suppressWarnings(train(price ~ ., data = train_xfw_ii, method = 'rpart', 
                trControl = cv, tuneLength = 10))
#mod_cv
#
# #Best Tuning Cp value
mod_cv$bestTune
```


```{r 'B32-Predict-cv-KC'}
# #Model Validation
# #Class of Both Models are different. rpart() require "vector" but "raw" is used with train()
class(mod_tree)
class(mod_cv)
#
#res_tree <- predict(mod_cv, test_xfw_ii, type  = "raw") 
res_cv <- test_xfw_ii %>% 
  mutate(CalY = predict(mod_cv, ., type = "raw"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
ii <- res_cv
summary(ii$Y_Yc)
#
# #Correlation 
cor(ii$price, ii$CalY)
#
# #RMSE: Root Mean Squared Error
sqrt(mean((ii$Y_Yc)^2))
#
# #MAE: Mean Absolute Error (MAE)
mean(abs(ii$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(ii$MAPE))
#
# #Accuracy 
1 - mean(abs(ii$MAPE))
```

## Plots

```{r 'B32-Tree-KC-Cp', include=FALSE}
# #rpart() for Tree Model using Tuned cp obtained from Cross-validation
# #Needed to plot this CV model 
mod_tree_cp <- rpart(price ~ ., data = train_xfw_ii, method = 'anova', cp = mod_cv$bestTune)
#
# #Very Long Output 
#summary(mod_tree)
hh <- mod_tree
```

```{r 'B32-Tree-KC-Cp-Set', include=FALSE}
hh <- mod_tree_cp
#
cap_hh <- "B32P03"
ttl_hh <- "KC: Tree by Crossvalidation"
loc_png <- paste0(.z$PX, "B32P03", "-KC-cv", ".png")
```

```{r 'B32P03-Save', include=FALSE, ref.label=c('B32-Tree-rpart')}
#
```

```{r 'B32P03', include=FALSE, fig.cap="This-Caption-NOT-Shown"}
knitr::include_graphics(paste0(.z$PX, "B32P03", "-KC-cv", ".png"))
```

```{r 'B32P0203', echo=FALSE, ref.label=c('B32P02', 'B32P03'), fig.cap="(B32P02, B32P03) KC: Two-part vs 10-part CV Tree"}
#
```

## Submission {.tabset .tabset-fade}

- Complete Code for EDA, Dummies, Partition, Decision Tree, Crossvalidation & Validation on KC House Data

### A {.unlisted .unnumbered}

### Code {.unlisted .unnumbered}

```{r 'B32-Submission-KC', eval=FALSE}
if(FALSE) {# #Data: KC House: Decision Trees: 2022-Feb-13
  #install.packages("dplyr", dependencies = TRUE)
  # #Load Packages (Install Packages if there is any error when loading the packages)
  library("dplyr")
  library("tibble")
  library("readr")
  library("tidyr")
  library("lubridate")
  library("fastDummies")
  library("rpart")
  library("rpart.plot")
  library("rattle")
  library("randomForest")
  library("caret")
  #
  # #Import from Clipboard - KC House Data - [21613 x 21]
  xxKC <- read_delim(clipboard())
  #
  # #Drop NA | Get Age | Dummy | Rename | Filter | Factor | Relevel Most Frequent Reference | 
  # #Drop | Relocate |
  xfw <- xxKC %>% 
    drop_na() %>% 
    #mutate(across(date, as_date)) %>% 
    mutate(sold = year(date), age = sold - yr_built) %>% 
    mutate(iRenew = ifelse(yr_renovated == 0, 0, 1)) %>% 
    rename(beds = bedrooms, baths = bathrooms, sqAbove = sqft_above, sqLot = sqft_lot, 
           iWater = waterfront, iView = view) %>% 
    filter(beds != 33) %>% 
    mutate(across(c(beds, baths, floors, iWater, iView, condition, grade, iRenew), factor)) %>% 
    mutate(across(c(zipcode), factor)) %>% 
    mutate(across(beds, relevel, ref = "3")) %>% 
    mutate(across(baths, relevel, ref = "2")) %>% 
    mutate(across(floors, relevel, ref = "1")) %>% 
    mutate(across(condition, relevel, ref = "3")) %>% 
    mutate(across(grade, relevel, ref = "7")) %>% 
    mutate(across(zipcode, relevel, ref = "98103")) %>% 
    select(-c(id, lat, long, date, sold, yr_renovated, yr_built, sqft_living, sqft_living15, sqft_lot15)) %>% 
    select(-c(zipcode)) %>% 
    relocate(price)
  #
  # #Structure: tibble [21,610 x 13]
  str(xfw)
  #
  # #Partition Data
  #
  # #Set Seed
  set.seed(3)
  #
  # #Create Dummies | Replaced All NA in original data so no replacement in dummy columns |
  dum_xfw <- dummy_cols(xfw, remove_first_dummy = TRUE, remove_selected_columns = TRUE) 
  idx_xfw <- sample.int(n = nrow(dum_xfw), size = floor(0.8 * nrow(dum_xfw)), replace = FALSE)
  train_xfw <- dum_xfw[idx_xfw, ] 
  test_xfw  <- dum_xfw[-idx_xfw, ]
  #
  # #Structure: tibble [17,288 x 50]
  #str(train_xfw)
  dim(train_xfw)
  #
  # #Decision Trees: Convert Dummy Variables to Factor Variables of two levels "0", "1"
  train_xfw_ii <- train_xfw %>% mutate(across(starts_with(c(
    "beds_", "baths_", "floors_", "iWater_", "iView_", "condition_", "grade_", "iRenew_")), factor))
  test_xfw_ii <- test_xfw %>% mutate(across(starts_with(c(
    "beds_", "baths_", "floors_", "iWater_", "iView_", "condition_", "grade_", "iRenew_")), factor))
  #
  # #Decision Tree Model
  mod_tree <- rpart(price ~ ., data = train_xfw_ii, method = 'anova')
  #
  # #Print Model - Long Text so not executed here.
  #mod_tree
  #summary(mod_tree)
  #
  # #Plot Tree
  #fancyRpartPlot(mod_tree, cex = .5)
  #
  # #Predict
  res_tree <- test_xfw_ii %>% 
    mutate(CalY = predict(mod_tree, ., type  = "vector"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
  #
  ii <- res_tree
  summary(ii$Y_Yc)
  #
  # #Correlation 70.2% 
  cor(ii$price, ii$CalY)
  #
  # #RMSE: Root Mean Squared Error
  sqrt(mean((ii$Y_Yc)^2))
  #
  # #MAE: Mean Absolute Error (MAE)
  mean(abs(ii$Y_Yc))
  #
  # #MAPE: Mean Absolute Percentage Error
  mean(abs(ii$MAPE))
  #
  # #Accuracy 63.4%
  1 - mean(abs(ii$MAPE))
  #
  # #Setup Parallel Crossvalidation
  cv <- trainControl(method = "repeatedcv", number = 10, repeats = 5, allowParallel = TRUE)
  #
  # #Decision Tree Model with Crossvalidation
  # #Ignore the Warning message: 
  # #In nominalTrainWorkflow ... : There were missing values in resampled performance measures.
  mod_cv <- suppressWarnings(train(price ~ ., data = train_xfw_ii, method = 'rpart', 
                  trControl = cv, tuneLength = 10))
  #
  # #Print Model
  #mod_cv
  #
  # #Best Tuning Cp value = 0.01111514
  mod_cv$bestTune
  #
  # #Predict
  res_cv <- test_xfw_ii %>% 
    mutate(CalY = predict(mod_cv, ., type  = "raw"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
  #
  ii <- res_cv
  summary(ii$Y_Yc)
  #
  # #Correlation 66.8% (decreased from 70.2 of mod_tree)
  cor(ii$price, ii$CalY)
  #
  # #RMSE: Root Mean Squared Error
  sqrt(mean((ii$Y_Yc)^2))
  #
  # #MAE: Mean Absolute Error (MAE)
  mean(abs(ii$Y_Yc))
  #
  # #MAPE: Mean Absolute Percentage Error
  mean(abs(ii$MAPE))
  #
  # #Accuracy 63.2% (decreased from 63.4% of mod_tree)
  1 - mean(abs(ii$MAPE))
  #
  # #Random Forest 
  if(FALSE) {# Random Forest is Horribly Slow. Run this code only if you hate your computer.
  # #NOTE: Following Parameter values are not too slow and explain 68.8% Var
    mod_frst <- randomForest(price ~ ., data = train_xfw_ii, ntrees = 500, sampsize = 5000, mtry = 8, nodesize = 10)
    print(mod_frst)
  #Call:
  # randomForest(formula = price ~ ., data = train_xfw_ii, ntrees = 500,      sampsize = 5000, mtry = 8, nodesize = 10) 
  #               Type of random forest: regression
  #                     Number of trees: 500
  #No. of variables tried at each split: 8
  #
  #          Mean of squared residuals: 41840392284
  #                    % Var explained: 68.85
  }
  #
  if(FALSE) {# Execute this code if you are trying to run the model on Test and following ERROR is observed
  # #ERROR: Type of predictors in new data do not match that of the training data.
    common <- intersect(names(train_xfw_ii), names(test_xfw_ii)) 
    for (p in common) { 
      if (class(train_xfw_ii[[p]]) == "factor") { 
        levels(test_xfw_ii[[p]]) <- levels(train_xfw_ii[[p]]) 
      } 
    }
  }
  #
  # #Accuracy of Random Forest
  if(FALSE){# Run This if mod_frst has been created
    res_frst <- test_xfw_ii %>% 
    mutate(CalY = predict(mod_frst, ., type  = "response"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
  #
  summary(res_frst$Y_Yc)
  sqrt(mean((res_frst$Y_Yc)^2)) # 211970.5
  mean(abs(res_frst$Y_Yc))      # 127049.8
  mean(abs(res_frst$MAPE))      # 0.2690059
  #
  # #Accuracy 73.2% (increased from 63.4% of mod_tree and 63.2% of mod_cv)
  1 - mean(abs(res_frst$MAPE))  # 0.7309941
  }
  #
  if(FALSE) {# #Variable Importance
    randomForest::importance(mod_frst)
    varImpPlot(mod_frst, sort = TRUE, n.var = 20, main = 'Top 20 Variables')
    # how many times these variables are used in building the trees
    #varUsed(mod_frst) 
  }
  #
  # #Model Performance on Test Data
  # #mod_tree : 63.4%
  # #mod_cv   : 63.2%
  # #mod_frst : 73.1%
}
```

## Postponed 

### Random forest

```{r 'B32-Forest', eval=FALSE}
# Random Forest is Horribly Slow. Keep it in separate chunk.
# #NOTE: Following Parameter values are not too slow and explain 68.8% Var
mod_frst <- randomForest(price ~ ., data = train_xfw_ii, 
                         ntrees = 500, sampsize = 5000, mtry = 8, nodesize = 10)
```

```{r 'B32-Print-Forest', eval=FALSE}
print(mod_frst)
```

### Error Rate

```{r 'B32-ErrorRate', eval=FALSE}
# #Plot to see Error Rates
plot(mod_frst)
```

### Tuning

- Parameter Tuning
  - This is for identifying optimal paraemets (mtree, and mtry)
  - First specify the independent variables (x) and dependent variables (y)
  - stepFactor: each iteration 'mtry' is inflated or deflated with the mentioned factor
  - plot: we need a plot to identify mtry or not (whether to plot out of bag error as a function of mtry)
  - ntreeTry: identified number of trees
  - trace allows to insert debugging code
  - improve: the relative improvement in OBB error must be by this much for the search to continue
  - Use extra = 'auto' or appropriate code for extra information

```{conjecture 'randomForest-length'}
\textcolor{brown}{Error in randomForest.default : length of response must be the same as predictors}
```

- Y needs to be vector. A tibble subsetted normally returns a tibble (even for single column) (unlike dataframe)

```{r 'B32-TuneModel', eval=FALSE}
tuneRF(x = data_train_ii[, -1], y = data_train_ii$price, stepFactor = 2, plot = TRUE, 
       ntreeTry = 150, improve = .05)
```

### Revised

- Use the tuned valued identified for revised model

```{r 'B32-Forest-Tuned', eval=FALSE}
# Random Forest is Horribly Slow. Keep it in separate chunk.
# #NOTE: ntree = 150
mod_frst_tuned <- randomForest(price ~ ., data = train_xfw_ii, 
                         ntree = 500, sampsize = 5000, mtry = 8, nodesize = 10)
```

```{r 'B32-Print-Forest-A', eval=FALSE}
print(mod_frst_tuned)
```

### Prediction

- Accuracy 56% - Improved on previous

```{r 'B32-Forest-Predict', eval=FALSE}
# #Model Validation
res_frst_tuned <- test_xfw_ii %>% 
  mutate(CalY = predict(mod_frst_tuned, ., type  = "response"), 
         Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
ii <- res_frst_tuned
summary(ii$Y_Yc)
#
# #Correlation 
cor(ii$price, ii$CalY)
#
# #RMSE: Root Mean Squared Error
sqrt(mean((ii$Y_Yc)^2))
#
# #MAE: Mean Absolute Error (MAE)
mean(abs(ii$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(ii$MAPE))
#
# #Accuracy 
1 - mean(abs(ii$MAPE))
```

### Importance

```{r 'B32-VarImp', eval=FALSE}
# #Variable Importance
randomForest::importance(mod_frst)
varImpPlot(mod_frst, sort = TRUE, n.var = 20, main = 'Top 20 Variables')
# how many times these variables are used in building the trees
#varUsed(mod_frst) 
```

## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B32-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ii, jj, kk, ll, cap_hh, cv, dum_xfw, hh, idx_xfw, idx_xsyw, loc_png, mod_cv, 
          mod_prune, mod_tree, mod_tree_cp, res_cv, res_prune, res_tree, test_xfw, test_xfw_ii, 
          train_xfw, train_xfw_ii, ttl_hh, xfw, xnw, xxB26CarDekho, xxB30KC, zfw, znw)
```

```{r 'B32-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
