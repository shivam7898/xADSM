# WIP (B32, Feb-13) {#b32 .unlisted .unnumbered}

```{r 'B32', include=FALSE, cache=FALSE, eval=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- "Decision Tree Algorithm"

## Packages

```{r 'B32-Installations', eval=FALSE}
if(FALSE){# #WARNING: Installation may take some time.
  install.packages("rpart", dependencies = TRUE)
}
```

## Decision Trees


## Woring on Feb-13 (B32)

## Partition
```{r 'B32-Partition-KC'}
# #Partition Data
set.seed(3)
# #Create Dummies | Replaced All NA in original data so no replacement in dummy columns |
dum_xfw <- dummy_cols(xfw, remove_first_dummy = TRUE, remove_selected_columns = TRUE) 
idx_xsyw <- sample.int(n = nrow(dum_xfw), size = floor(0.8 * nrow(dum_xfw)), replace = FALSE)
train_xfw <- dum_xfw[idx_xsyw, ] 
test_xfw  <- dum_xfw[-idx_xsyw, ]
```

## Model Rpart


```{r 'B-'}
modelLookup('rpart')
```

## Tree

- If anova is not mentioned then it will create a classification model. Anova ensures that it is a regression model i.e. dependent is continuous


- IF there is a problem in plotting then mention the cp parameter in rpart() with the earlier identified value

```{r 'B-'}
ii <- train_xfw %>% mutate(across(starts_with(c("s_", "f_", "t_", "o_")), factor))
test_ii <- test_xfw %>% mutate(across(starts_with(c("s_", "f_", "t_", "o_")), factor))

#tree_1 <- rpart(price ~.,data = train_xfw, method= 'anova')
tree_2 <- rpart(price ~.,data = ii, method= 'anova')
```

## Plot



```{r 'B-'}
plot(tree_2)
text(tree_2,pretty= 1)
```


```{r 'B-'}
#tree_2
```

## Summary

- Very Long Output 

```{r 'B-'}
#summary(tree_2)
```


## Fancy


```{r 'B-'}
fancyRpartPlot(tree_2, cex = .48)
```

## Predict

- Prediction Accuracy is only 35%


```{r 'B-'}
## PREDICT THE MODEL
#predicted <- predict(tree_2, test_ii, type  = "vector") 
#
#
res_lll <- test_ii %>% 
  mutate(CalY = predict(tree_2, ., type  = "vector"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
summary(res_lll$Y_Yc)
#
# #RMSE: Root Mean Squared Error
#res_w %>% summarise(across(everything(), ~ sqrt(mean((.)^2))))
sqrt(mean((res_lll$Y_Yc)^2))

#
# #MAE: Mean Absolute Error (MAE)
#res_w %>% summarise(across(everything(), ~ mean(abs(.))))
mean(abs(res_lll$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(res_lll$MAPE))
#
# #Accuracy 
1 - mean(abs(res_lll$MAPE))
```

## Cleaning Names


```{r 'B-'}
data_train_ii <- clean_names(ii)
data_test_ii <- clean_names(test_ii)
```

## Setup Parallel

- Allow Parallel

```{r 'B-'}
cv <- trainControl(method = "repeatedcv", number = 10, repeats = 5, allowParallel = TRUE)
```


## Crossvalidation

- Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.

- https://stackoverflow.com/questions/26828901/warning-message-missing-values-in-resampled-performance-measures-in-caret-tra

- If this is regression, the most likely case is that the tree did not find a good split and used the average of the outcome as the predictor. It is fine but you cannot calculate R^2 since the variance of the predictions is zero.

- For now, assumed that the warning is not importnat - "ForLater"

```{r 'B-'}
tree_3 <- train (price ~.,
                 data = data_train_ii, method= 'rpart',
                 trControl = cv, tuneLength = 10)
```

- cp = 0.008528435

```{r 'B-'}
tree_3
```

## Predict Model 3

- Accuracy improved to 42%

```{r 'B-'}
## PREDICT THE MODEL
#predicted <- predict(tree_2, test_ii, type  = "vector") 
#
# #Class of Both are different. Rpart can have "vector", use "raw" with train
class(tree_2)
class(tree_3)

res_3 <- data_test_ii %>% 
  mutate(CalY = predict(tree_3, ., type  = "raw"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
summary(res_3$Y_Yc)
#
# #RMSE: Root Mean Squared Error
#res_w %>% summarise(across(everything(), ~ sqrt(mean((.)^2))))
sqrt(mean((res_3$Y_Yc)^2))

#
# #MAE: Mean Absolute Error (MAE)
#res_w %>% summarise(across(everything(), ~ mean(abs(.))))
mean(abs(res_3$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(res_3$MAPE))
#
# #Accuracy 
1 - mean(abs(res_3$MAPE))
```

## Random forest
- Definitely Slow

```{r 'B-'}
# building random forest with ntree (500 default) and mtry(square root of p)
mod_rf1 <- randomForest(price ~., data = data_train_ii)
print(mod_rf1)
```

## Error Rate


```{r 'B-'}
# TO SEE ERROR RATE 
plot(mod_rf1)
```

## Tuning

- PARAMETER TUNING
This is for identifying optimal paraemets (mtree, and mtry)
first specifying the IVs and Dv
stepFactor: each iteration mtry is inflated or deflated with the mentioned factor
plot: we need a plot to identify mtry or not (whether to plot out of bag error as a function of mtry)
ntreeTry: identified number of trees
trace allows to insert debugging code
improve:the relative improvement in OBB error must be by this much for the search to continue

x are independent variables, y is the response


- Error in randomForest.default(x, y, mtry = mtryStart, ntree = ntreeTry, : 
length of response must be the same as predictors
- Probably because of conflict with ggplot margin() - NO did not work

- Y needs to be vactor


```{r 'B-'}
#str(data_train_ii[, -1])
str(data_train_ii[, 1])
str(data_train_ii$price)
```


```{r 'B-'}
tuneRF(x = data_train_ii[, -1], y = data_train_ii$price, stepFactor = 2, plot = TRUE, 
       ntreeTry = 150, improve = .05)

```

## Revised

- Random Forest is SLow. Keep the chunk separate
```{r 'B-'}
# use the revised model
mod_rf2 <- randomForest(price ~., data = data_train_ii, ntree = 150, mtry = 8)
```


```{r 'B-'}
print(mod_rf2)
```


## Prediction

- Accuracy 56% - Improved on previous

```{r 'B-'}
## PREDICT THE MODEL
#predicted3 <- predict(mod_rf2, data_test_ii, type  = "response")  # predict selling_price  


####S Calculate prediction accuracy and error rates
# make actuals_predicteds dataframe.
#actuals_preds3 <- data.frame(cbind(actuals=data_test$selling_price, predicteds=predicted3))

#Root mean squared error
#sqrt(mean((actuals_preds3$actuals - actuals_preds3$predicteds)^2))

res_rf <- data_test_ii %>% 
  mutate(CalY = predict(mod_rf2, ., type  = "response"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
summary(res_rf$Y_Yc)
#
# #RMSE: Root Mean Squared Error
#res_w %>% summarise(across(everything(), ~ sqrt(mean((.)^2))))
sqrt(mean((res_rf$Y_Yc)^2))

#
# #MAE: Mean Absolute Error (MAE)
#res_w %>% summarise(across(everything(), ~ mean(abs(.))))
mean(abs(res_rf$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(res_rf$MAPE))
#
# #Accuracy 
1 - mean(abs(res_rf$MAPE))
```


## Importance

```{r 'B-'}
# To understand variable importance
varImpPlot(mod_rf2, sort = TRUE, n.var = 10, main = 'TOP TEN VARIABLES')
```


```{r 'B-'}
randomForest::importance(mod_rf2)
```

```{r 'B-'}
# how many times these variables are used in building the trees
varUsed(mod_rf2) 
```

## KC

```{r 'B26-GetKC', include=FALSE}
# #Load Data: KC House
xxB30KC <- f_getRDS(xxB30KC)
```


```{r 'B30-PrepKC'}
aa <- xxB30KC
# #Drop NA | Get Age | Dummy | Rename | Filter | Factor | Relevel Most Frequent Reference | 
# #Drop | Relocate | 
bb <- aa %>% 
  drop_na() %>% 
  #mutate(across(date, as_date)) %>% 
  mutate(sold = year(date), age = sold - yr_built) %>% 
  mutate(iRenew = ifelse(yr_renovated == 0, 0, 1)) %>% 
  rename(beds = bedrooms, baths = bathrooms, sqAbove = sqft_above, sqLot = sqft_lot, 
         iWater = waterfront) %>% 
  filter(beds != 33) %>% 
  mutate(across(c(beds, baths, floors, iWater, condition, grade, iRenew), factor)) %>% 
  mutate(across(beds, relevel, ref = "3")) %>% 
  mutate(across(baths, relevel, ref = "2")) %>% 
  mutate(across(floors, relevel, ref = "1")) %>% 
  mutate(across(condition, relevel, ref = "3")) %>% 
  mutate(across(grade, relevel, ref = "7")) %>% 
  select(-c(id, view, zipcode, lat, long, date, sold, yr_renovated, yr_built, 
            sqft_living, sqft_living15, sqft_lot15)) %>% 
  relocate(price)
#
xfw <- bb
zfw <- xfw %>% mutate(across(where(is.numeric), ~ as.vector(scale(.)))) 
xnw <- xfw %>% select(where(is.numeric))
znw <- zfw %>% select(where(is.numeric))
f_wl(znw)
```


```{r 'B-'}
str(xfw)
```

## Partition

```{r 'B32-Partition-KC'}
# #Partition Data
set.seed(3)
# #Create Dummies | Replaced All NA in original data so no replacement in dummy columns |
dum_xfw <- dummy_cols(xfw, remove_first_dummy = TRUE, remove_selected_columns = TRUE) 
idx_xsyw <- sample.int(n = nrow(dum_xfw), size = floor(0.8 * nrow(dum_xfw)), replace = FALSE)
train_xfw <- dum_xfw[idx_xsyw, ] 
test_xfw  <- dum_xfw[-idx_xsyw, ]
```



```{r 'B-'}

dim(train_xfw)
```


```{r 'B-'}
names(train_xfw)
```


```{r 'B-'}
ii <- train_xfw %>% mutate(across(starts_with(c("beds_", "baths_", "floors_", "iWater_", "condition_",
                                                "grade_", "iRenew_1")), factor))
tree_1 <- rpart(price ~.,data = ii, method= 'anova')
#tree_2 <- rpart(price ~.,data = ii, method= 'anova')
```


```{r 'B-'}
plot(tree_1)
text(tree_1, pretty= 1)
```


```{r 'B-'}
#summary(tree_1)
fancyRpartPlot(tree_1, cex = .48)
```



- Prediction Accuracy is only 63%

```{r 'B-'}
## PREDICT THE MODEL
test_ii <- test_xfw %>% mutate(across(starts_with(c("beds_", "baths_", "floors_", "iWater_", "condition_",
                                                "grade_", "iRenew_1")), factor))
#predicted <- predict(tree_1, test_ii, type  = "vector") 
#
#
res_lll <- test_ii %>% 
  mutate(CalY = predict(tree_1, ., type  = "vector"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
summary(res_lll$Y_Yc)
#
# #RMSE: Root Mean Squared Error
#res_w %>% summarise(across(everything(), ~ sqrt(mean((.)^2))))
sqrt(mean((res_lll$Y_Yc)^2))

#
# #MAE: Mean Absolute Error (MAE)
#res_w %>% summarise(across(everything(), ~ mean(abs(.))))
mean(abs(res_lll$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(res_lll$MAPE))
#
# #Accuracy 
1 - mean(abs(res_lll$MAPE))
```


## Setup Parallel

- Allow Parallel
- Result CP =  0.01110916

```{r 'B-'}
cv <- trainControl(method = "repeatedcv", number = 10, repeats = 5, allowParallel = TRUE)
```


```{r 'B-'}
tree_3 <- train (price ~.,
                 data = ii, method= 'rpart',
                 trControl = cv, tuneLength = 10)
```


```{r 'B-'}
tree_3
```

## Prediction of Crossvalidation

- Accuracy 63%
 - NO improvement
 - Do not know difference between Raw and Vector

```{r 'B-'}
## PREDICT THE MODEL
#test_ii <- test_xfw %>% mutate(across(starts_with(c("beds_", "baths_", "floors_", "iWater_", "condition_",
                                                #"grade_", "iRenew_1")), factor))
#predicted <- predict(tree_1, test_ii, type  = "vector") 
#
#
res_3 <- test_ii %>% 
  mutate(CalY = predict(tree_3, ., type  = "raw"), Y_Yc = price - CalY, MAPE = Y_Yc / price)
#
summary(res_3$Y_Yc)
#
# #RMSE: Root Mean Squared Error
#res_w %>% summarise(across(everything(), ~ sqrt(mean((.)^2))))
sqrt(mean((res_3$Y_Yc)^2))

#
# #MAE: Mean Absolute Error (MAE)
#res_w %>% summarise(across(everything(), ~ mean(abs(.))))
mean(abs(res_3$Y_Yc))
#
# #MAPE: Mean Absolute Percentage Error
mean(abs(res_3$MAPE))
#
# #Accuracy 
1 - mean(abs(res_3$MAPE))
```

## Random Forest

```{r 'B-'}
# building random forest with ntree (500 default) and mtry(square root of p)
mod_rf1 <- randomForest(price ~., data = data_train_ii)
print(mod_rf1)
```




## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B32-Cleanup', include=FALSE, cache=FALSE, eval=FALSE}
f_rmExist(aa, bb, ii, jj, kk, ll)
```

```{r 'B32-Validation', include=FALSE, cache=FALSE, eval=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
