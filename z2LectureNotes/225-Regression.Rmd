# Regresssion (B25, Dec-26) {#b25}

```{r 'B25', include=FALSE, cache=FALSE}
sys.source(paste0(.z$RX, "A99Knitr", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "000Packages", ".R"), envir = knitr::knit_global())
sys.source(paste0(.z$RX, "A00AllUDF", ".R"), envir = knitr::knit_global())
#invisible(lapply(f_getPathR(A09isPrime), knitr::read_chunk))
```

## Overview

- "Supervised Learning Algorithm: Regression"

## Packages

```{r 'B25-Installations', eval=FALSE}
if(FALSE){# #WARNING: Installation may take some time.
  install.packages("fastDummies", dependencies = TRUE)
  install.packages("carData", dependencies = TRUE)
}
```

## Linear Regression {.tabset .tabset-fade}

```{r 'B25D01', comment="", echo=FALSE, results='asis'}
f_getDef("Simple-Linear-Regression")
```

- ${Y}$: Scalar response, Dependent variable, Outcome variable, Target, Predicted
- ${X}$: Explanatory variables, Independent variables, Antecendent variables, Predictors

- It is applied when the objective is to predict the outcome variable based on the antecendent variables
- Predicted (Y) should be continuous, but Predictors (X) can be either continuous or categorical 
  - Ex: Salary (Y) is a function of Age, Gender, Education, Years of Experience
  - Ex: Consumption (Y) is a function of Income (X)
  - We are interested in $Y = mX + C$ where ${m}$ is the slope of the line and C is the y-intercept
    - Slope: What is the change in Y for unit change in X
  - Because there will be some error ${\epsilon}$, thus the equation is given by $y = {\alpha} + {\beta}x + {\epsilon}$ where ${\alpha}$ is the average Y when X are zero.
  - NOTE Equation can also be given by ${y} = {\beta}_0 + {\beta}_1 {x} + {\epsilon}$. In that case assume ${\alpha} = {\beta}_0$ and ${\beta} = {\beta}_1$.

- \textcolor{pink}{Question:} ${\alpha}$ is constant for a given set of data
  - Yes

- Refer [Slope is tested for Significance](#beta1-c14 "c14")
- Simple Linear Regression is also known as \textcolor{pink}{Bivariate Regression}. i.e. Single Y, Single X
- When there are Single Y and Multiple X, it is called \textcolor{pink}{Multiple Linear Regression}
  - Equation: ${y} = {\beta}_0 + {\beta}_1 {x}_1 + {\beta}_2 {x}_2 + \ldots + {\epsilon}$

- \textcolor{pink}{lm()}
  - Base R Function to run linear model or regression
  - Tilde "~" means regressed on i.e. Dependent (Y) ~ Independents (X)
    - "linear regression model of y on x"
  - Models for lm are specified symbolically. A typical model has the form \textcolor{pink}{response ~ terms} where \textcolor{pink}{response} is the (numeric) response vector and \textcolor{pink}{terms} is a series of terms which specifies a linear predictor for response. 
  - \textcolor{pink}{summary()}
    - The standard error is variability to expect in coefficient which captures sampling variability so the variation in intercept can be up 0 and variation in IncomeX will be 0 not more than that
    - t-value: t value is Coefficient divided by standard error.
      - It is basically how big is estimated relative to error.
      - Bigger the coefficient relative to Std. error the bigger the t score and t score comes with a p-value because it is a distribution.
    - p-value is how statistically significant the variable is to the model for a confidence level of 95%
      - If the p-value is less than alpha (0.05) for both intercept and X then it implies that both are statistically significant to our model.
    - Residual standard error or the standard error of the model is basically the average error for the model. It means the average value by which our model can deviate while predicting the Y. 
      - Lesser the error the better the model while predicting.
    - Multiple R-squared is the ratio of (1-(sum of squared error/sum of squared total))
    - Adjusted R-squared:
      - If we add variables no matter if its significant in prediction or not the value of R-squared will increase which the reason Adjusted R-squared is used because if the variable added is not significant for the prediction of the model the value of Adjusted R-squared will reduce, it is one of the most helpful tools to avoid overfitting of the model.
   - F-statistic is the ratio of the mean square of the model and mean square of the error, in other words, it is the ratio of how well the model is doing and what the error is doing, and the higher the F value is the better the model is doing as compared to the error.
   
### lm() {.unlisted .unnumbered}

```{r 'B25-Model'}
bb <- tibble(ConsumptionY = seq.int(80, by = 20, length.out = 5),
             IncomeX = seq.int(100, by = 100, length.out = 5))
#
# #Build the model
mod_bb <- lm(formula = ConsumptionY ~ ., data = bb)
#
# #Model
suppressWarnings(mod_bb)
#
# #Summarise the model
if(FALSE) suppressWarnings(summary(mod_bb))
#
# #ANOVA Table
if(FALSE) suppressWarnings(anova(mod_bb))
```

### Model {.unlisted .unnumbered}

```{r 'B25-lmModel'}
names(mod_bb)
#
# #Coefficients (Model Parameters): Different headers than summary(mod_bb)$coefficients 
mod_bb$coefficients #coefficients(mod_bb)
#
# #Residuals
mod_bb$df.residual
#
f_pNum(mod_bb$residuals) #residuals(mod_bb) #summary(mod_bb)$residuals 
#
# #What is Effects
f_pNum(mod_bb$effects) #effects(mod_bb)
#
# #Rank
mod_bb$rank
#
# #Fitted Values
mod_bb$fitted.values #fitted.values(mod_bb)
#
# #Assign
mod_bb$assign
#
# #qr
mod_bb$qr[[1]] %>% as_tibble()
#
# #Others
if(FALSE) mod_bb$xlevels
if(FALSE) mod_bb$call #summary(mod_bb)$call
if(FALSE) mod_bb$terms
#
mod_bb$model
```

### Summary {.unlisted .unnumbered}

```{r 'B25-lmSummary'}
#summary(mod_bb)
names(suppressWarnings(summary(mod_bb)))
# [1] "call"          "terms"         "residuals"     "coefficients"  "aliased"       "sigma"        
# [7] "df"            "r.squared"     "adj.r.squared" "fstatistic"    "cov.unscaled" 
#
# #Coefficients: Different headers than mod_bb$coefficients
f_pNum(suppressWarnings(summary(mod_bb))$coefficients) %>% as_tibble()
#
#
# #Better Printing
if(FALSE) f_pNum(summary(mod_bb)$coefficients) %>% as_tibble(rownames = "DummyParVsRef") %>% 
  rename(pVal = "Pr(>|t|)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #R^2 and Adjusted R^2
suppressWarnings(summary(mod_bb))$r.squared
suppressWarnings(summary(mod_bb))$adj.r.squared
#
# #F-Statistic
suppressWarnings(summary(mod_bb))$fstatistic 
#
# #Covariance
suppressWarnings(summary(mod_bb))$cov.unscaled
#
# #Sigma
f_pNum(suppressWarnings(summary(mod_bb))$sigma)
```

## Prediction

- \textcolor{pink}{Question:} After generating the equation can we calculate what would be the Consuption if the Income is 600
  - The model can be used to predict the dependent variable
  - (Aside) \textcolor{orange}{Caution:} Prediction beyond the values of min(x) and max(x) of original dataset is inference and it is discouraged. i.e. Y for X= 150 can be predicted but Y for X >500 should be avoided.

```{r 'B25-lmPredict'}
# #Predict the Outcome variable using the Model
test_bb <- tibble(IncomeX = c(150, 600, 700))
#res_bb <- predict(mod_bb, test_bb)
res_bb <- test_bb %>% mutate(ConsumptionY = predict(mod_bb, .))
res_bb
```

## MS Excel: Regression Analysis

- We need Data Analysis AddIn.
- In Windows 10 & Microsoft Excel 2016 
  - Menu | File | Options | Add-ins | Manage = Excel Add-ins | Go | Add-ins Popup 
    - Tick the Analysis ToolPak | Go
    - As shown by Professr, the Sequence might be Menu | File | More | Options | ...
  - Confirmation
    - Menu | Data | 
      - Right Most section would have been added called "Analysis" and it will have one button "Data Analysis"

- Regression Analysis
  - Enter the data
    - Menu | Data | Analysis | Data Analysis | Popup | Regression | OK
    - Select Input Y Range | Select Input X Range | Tick Labels | OK 

```{r 'B25P01', echo=FALSE, out.width='100%', fig.cap="(B25P01) Regression in MS Excel"}
knitr::include_graphics(paste0(.z$PX, "B25P01-Excel-Analysis.jpg"))
```

```{r 'B25P02', echo=FALSE, out.width='100%', fig.cap="(B25P02) Regression Result in MS Excel"}
knitr::include_graphics(paste0(.z$PX, "B25P02-Excel-Regression-Result.jpg"))
```

## Explanation of Terms


```{r 'B25D02', comment="", echo=FALSE, results='asis'}
f_getDef("H-SimpleRegression")
```

- t-value:
  - The slope model parameter $(\beta_1)$ needs to be tested for significance.
  - Refer [Slope is tested for Significance](#beta1-c14 "c14")
  - $t = \frac{b_1}{s_{b_1}}$
  - If ${}^2\!P_{(t)} \leq {\alpha} \to {H_0}$ Rejected.

```{r 'B25D03', comment="", echo=FALSE, results='asis'}
f_getDef("Standard-Error-B1")
```

- \textcolor{pink}{Question:} In case of multiple variables, do we need to do this for all variables
  - No, we will not do it individually. We will do multiple regression. We will incorporate all the variables simultaneously.
  - In multiple regression, we get $\{\beta_1, \beta_2, \beta_3, \ldots \}$ and each will have its own standard error i.e. $\{s_{b_1}, s_{b_2}, s_{b_3}, \ldots \}$.
  - If a variable is NOT signifact, it means that it is not contributing to the model in a meaningful manner.

- F-Statistic:
  - For simple linear regression i.e. single X, single Y; the F-test and t-test provide same result. However, in multiple regression model F-test is used as the test for \textcolor{pink}{overall significance} and t-tests are used as tests for \textcolor{pink}{individual significance}.

```{r 'B25D07', comment="", echo=FALSE, results='asis'}
f_getDef("H-MultipleRegression-F")
```

```{r 'B25D08', comment="", echo=FALSE, results='asis'}
f_getDef("H-MultipleRegression-t") 
```


- \textcolor{pink}{Question:} Which one should come first Joint Significance or Individual Significance
  - In multiple regression analysis, the joint significance needs to be looked at first.
  - i.e. First the variables jointly able to predict the outcome variable then later on we can check contribution of individual variable
  - If the model is not good then there is no point in looking at individual variables
  - F should be greater than 0.05 for us to consider that model is valid.

- \textcolor{pink}{Question:} Can we drop the variables which are not contributing much to the model
  - We may find that out of 4 independent variable A, B, C, D; C & D are not contributing much to the model. We can drop C & D. However, there is a possibility that A & B are performing well because of the presence of C & D. Though C & D contribution, by itself, is insignificant, it makes A & B contribution significant. C or D might be influencing A or B.
  - If there are high number of variables e.g. 20 or 30, then we will drop the insignificant variables because the model complexity becomes an issue.
    - Practically how many independent variable we can handle in our business case is also a consideration
  
- \textcolor{pink}{Question:} Here we have single $\beta_1$ then how the F-test is applied
  - We are only checking $\beta_1 = 0$

- Any model is a good model if it has minimum number of predictors and maximum predictive power.


```{r 'B25D04', comment="", echo=FALSE, results='asis'}
f_getDef("Coefficient-of-Determination") 
```

- $r^2$ is the 'Coefficient of Determination' or 'Goodness of Fit'
  - $r^2 = 1$ means model is able to explain 100% relationship between independent and dependent variables.
  - $r^2 = 0$ means model is not able to explain anything
  


```{r 'B25D05', comment="", echo=FALSE, results='asis'}
f_getDef("Error-Term")
```

- Error Term $\epsilon$ denotes unexplained variance
  
- \textcolor{pink}{Question:} What would be the acceptable value of $r^2$
  - No rule, context dependent
  - In general, we want $r^2$ to be as high as possible
  - (Aside) Further, there is a 'model overfitting' concern also with very high $r^2$

- Total = Explained (by independent variables) + Unexplained ($\epsilon$)
  - Join Significance is about all the independent variables


- \textcolor{pink}{Question:} Is there a possibility of situation where independent variables are not performing jointly but $r^2$ is high
  - It is possible
  - There might be some internal issue which results in high $r^2$ but low model performance
  - If the predictors are highly correlated (Multicollinearity)
    - Individual performance gets reduced, however, the $r^2$ value might increase
    - Multicollinearity reduces the robustness of model
    - Individually the either variable can explain the dependent variable very well. However, due to multicollinearity, together they fail to perform at same level.
    - Multicollinearity is not a problem between depdendent and independent variable. It is applicable only between independent variables.
  - Regression analysis require that the variables should be non-overlapping (high correlation should not be there)


```{r 'B25D06', comment="", echo=FALSE, results='asis'}
f_getDef("Multicollinearity")
```

- \textcolor{pink}{Question:} How do we deal with Multicollinearity and other such problems
  - First of all, you need to select those independent variables which are not correlated to each other

- Multiple R (in Excel)
  - Average correlation between all the variables (dependent and independent)


```{r 'B25D09', comment="", echo=FALSE, results='asis'}
f_getDef("RSq-Adj")
```


- Adjusted R square $R_a^2$
  - If we want to compare different models (and specially those with different number of independent variables), we should use Adjusted $R_a^2$
  
## Application of Regression {#app-reg-b25}

- Two Applications of Regression
  - Estimation (Descriptive)
    - Which of these independent variables significantly affect the dependent variable
    - e.g. Which of these factors are influencing the employee performance
    - When we are doing estimation, data partition into train and test datasets is not required.
  - Prediction
    - Partition the Sample data randomly into Train and Test datasets in ratio of 80:20, 70:30 etc.
    - Do not predict beyond the min(x) and max(x) range because no data is available outside these limits.
    - Validation 
      - Randomly Partition data | Build the Model on Train | Run it on Test | For Test we will have actual Y and predicted Y $(\hat{y})$ | Evaluate the difference between Actual and Predicted ${(y_i - \hat{y}_i)}$
      - The error between Actual and Predicted is called \textcolor{pink}{loss function}.
      - For all the models do this and compare them and select the one which have lowest loss function.


- \textcolor{pink}{Question:} More number of observations in Train dataset would lead to better model
  - Yes. That is why Train would have the major chunk. For small datasets it would be around 80%
- \textcolor{pink}{Question:} What is the drawback if Train contains 80% for large datasets
  - No issue.
  - Partition should be done randomly, otherwise no limitation.


## Bias-Variance Tradeoff

- Refer [Bias-Variance Tradeoff](#bias-var-c37 "c37")


```{r 'B25D10', comment="", echo=FALSE, results='asis'}
f_getDef("Bias-variance-Trade-off")
```

```{r 'B25D11', comment="", echo=FALSE, results='asis'}
f_getDef("Overfitting")
```

## Categorical Independent Variables

- Refer [Categorical Independent Variables](#reg-cat-c15 "c15")

```{r 'B25D12', comment="", echo=FALSE, results='asis'}
f_getDef("Dummy-Variables") #dddd
```

- When the independent variable is categorical e.g. Gender (M, F)
  - Then "one unit change in X" is not applicable 
  - It is more about "change in state of X" from one level to another.
  - Convert Categorical Independent Variable into Dummy Variables.
  - The category that is not assigned an indicator variable is denoted the \textcolor{pink}{reference category} (or the Benchmark). 
    - If 'M' is assigned 0 then it will be the benchmark
    - If 'F' is assigned 0 then it will be the benchmark
    - Performance of all other levels of the variable is given as compared to the referenced level
  - In the example above 'high' is the benchmark
  - "dummy coding" leads to the creation of a table called \textcolor{pink}{contrast matrix}.

- \textcolor{pink}{Question:} What if we have a dataset with both categorical and continuoud dependent varaibles
  - Convert categorical to dummies, no need to do anything with continous variables

## Example 

```{conjecture 'lm-non-numeric-y'}
\textcolor{brown}{Warning messages: In model.response(mf, "numeric") : using type = "numeric" with a factor response will be ignored}
```

- Additional Warnings
  - \textcolor{brown}{"In Ops.factor(y, ...) : '-' not meaningful for factors"} 
- Running summary() on this Model will result in Error
  - \textcolor{brown}{"Error in quantile.default(resid) : (unordered) factors are not allowed"} 
  - \textcolor{brown}{"In addition: Warning message: In Ops.factor(r, 2) : '^' not meaningful for factors"}
- Running step() on this Model will resutl in Error
  - \textcolor{brown}{"Error in step(...) : AIC is -infinity for this model, so 'step' cannot proceed"}
- Dependent Variable is Non-numeric. Found to be Factor in this case.
- Y needs to be Numeric for Regression Analysis


```{r 'B25-lmExample'}
# #Create Data Set with Factor Column having the its First Level as the Reference for Later
bb <- tibble(Performance = c(35, 36, 40, 45, 60, 66, 67, 78, 80, 87, 78, 89, 89, 90),
             Class = factor(c(rep("A", 4), rep("B", 6), rep("C", 4)), levels = c("C", "B", "A")))
#
# #Create Dummies | Drop Original | Drop Reference Variable 
dum_bb <- dummy_cols(bb, select_columns = "Class", 
                     remove_selected_columns = TRUE, remove_first_dummy = TRUE)
str(dum_bb)
#
mod_bb <- lm(Performance ~ ., data = bb)
if(FALSE) summary(mod_bb)$coefficients
# #Better Printing
if(TRUE) f_pNum(summary(mod_bb)$coefficients) %>% as_tibble(rownames = "DummyParVsRef") %>% 
  rename(pVal = "Pr(>|t|)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Anova Table 
if(FALSE) anova(mod_bb) 
if(TRUE) anova(mod_bb) %>% as_tibble(rownames = "Predictors") %>% 
  rename(pVal = "Pr(>F)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
```


## fastDummies

- \textcolor{pink}{dummy_cols()}
  - To generate dummy columns
  - If NA are present, then by default, an NA dummy column is also created.
    - \textcolor{orange}{Caution:} The other columns would have {0, 1, NA} in this case. For now those NA are being set to 0 manually. Impact of keeping these NA as it is and handling it inside model would be observed "ForLater"
  
  
```{r 'B25-Dummy'}
set.seed(3) 
bb <- tibble(Performance = sample(1:100, size = 20),
             Grade = sample(LETTERS[1:3], size = 20, replace = TRUE))
str(bb, vec.len = 10)
#
# #Convert character to dummy columns 
if(FALSE) dum_bb <- dummy_cols(bb, select_columns = c("Grade"))
# #To keep only (k-1) columns to avoid multicollinearity
if(FALSE) dum_bb <- dummy_cols(bb, select_columns = c("Grade"),  
                              remove_first_dummy = FALSE, remove_selected_columns = TRUE)
if(TRUE) dum_bb <- dummy_cols(bb, select_columns = c("Grade"), 
                              remove_most_frequent_dummy = TRUE, remove_selected_columns = TRUE)
str(dum_bb, vec.len = 10)
#
# #Multiple Linear Regression with Categorical to Dummy Variables
if(FALSE) mod_bb <- lm(formula = Performance ~ Grade_A + Grade_B, data = dum_bb)
if(TRUE) mod_bb <- lm(formula = Performance ~ ., data = dum_bb)
#
# #Model
mod_bb
#
# #Summarise the model
if(TRUE) summary(mod_bb)
#
# #ANOVA Table
if(TRUE) anova(mod_bb)
```

## Data: CarDekho 

- Covered in Next Lecture.

## Data: Salaries {.tabset .tabset-fade}

### Salaries {.unlisted .unnumbered}

```{r 'B25-DataSalaries'}
# #Load Data "Salaries". It is NOT included in "car". It is included in the "carData" Package
if(FALSE) data(package = "car")$results[ , "Item"]
data("Salaries", package = "carData")
str(Salaries)
```

### Categorical X with 2 levels {.unlisted .unnumbered}


```{r 'B25-1X2l'}
# #y = b0 + b1 * x : Y (Salaries), X (Sex) with 2 levels
#
# #In R "Factor" Notation (Default Alphabetical Ordering): Female = 1, Male = 2 
levels(Salaries$sex)
#
# #To encode categorical variables, known as 'contrast coding systems'. 
# #R can directly convert the Categorical Variable into dummy with Female = 0, Male = 1
# #The default option in R is to use the first level of the factor as a reference 
# #and interpret the remaining levels relative to this level.
# #contrasts() lists the dummy variables that would be created for k levels i.e. k-1 dummy 
contrasts(Salaries$sex)
#
# #Compute the model
mod_sal_f <- lm(salary ~ sex, data = Salaries)
if(TRUE) f_pNum(summary(mod_sal_f)$coefficients) %>% as_tibble(rownames = "DummyParVsRef") %>% 
  rename(pVal = "Pr(>|t|)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Interpretation of Coefficients with 'Female' as the reference level i.e. 0 within the dummy 
# # b0 : average salary among Female (Reference): (Intercept, Estimate) 101002
# # b0 + b1 : average salary among Male : (101002) + (14088) = 115090
# # b1 : average difference in salary of Male & Female (Reference): (sexMale, Estimate) 14088
#
# #The p-value is 0 (significant), suggesting that there is a statistical evidence 
# #of a difference in average salary between the genders
#
# #We can change the Factor Levels and thus change the Reference Variable
m_Salaries <- as_tibble(Salaries) %>% mutate(across(sex, factor, levels = c("Male", "Female")))
levels(m_Salaries$sex)
contrasts(m_Salaries$sex)
#
mod_sal_m <- lm(salary ~ sex, data = m_Salaries)
if(TRUE) f_pNum(summary(mod_sal_m)$coefficients) %>% as_tibble(rownames = "DummyParVsRef") %>% 
  rename(pVal = "Pr(>|t|)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Interpretation of Coefficients with 'Male' as the reference level i.e. 0 within the dummy 
# # b0 : average salary among Male (Reference): (Intercept, Estimate) 115090
# # b0 + b1 : average salary among Female : (115090) + (-14088) = 101002
# # b1 : average difference in salary of Female & Male (Reference): (sexFemale, Estimate) -14088
#
# #The fact that the coefficient for sexFemale in the regression output is negative 
# #indicates that being a Female is associated with decrease in salary (relative to Male).
#
# #The p-value is 0 (significant)
```


### Categorical X with 3 levels {.unlisted .unnumbered}

```{r 'B25-1X3l'}
# #y = b0 + b1 * x : Y (Salaries), X (Rank) with 3 levels
#
# #Change Factor Levels | Treating Professor as Reference Variable 
# #Ordering is done in decreasing Rank but NOT as 'Ordered Factor' for now
r_Salaries <- as_tibble(Salaries) %>% 
  mutate(across(rank, factor, levels = c("Prof", "AssocProf", "AsstProf")))
levels(r_Salaries$rank)
#
# #contrasts() lists the dummy variables that would be created for k levels i.e. k-1 dummy 
# #Two dummies were created against the reference of "Prof"
contrasts(r_Salaries$rank)
#
mod_sal_r <- lm(salary ~ rank, data = r_Salaries)
if(TRUE) f_pNum(summary(mod_sal_r)$coefficients) %>% as_tibble(rownames = "DummyParVsRef") %>% 
  rename(pVal = "Pr(>|t|)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Interpretation of Coefficients with 'Prof' as the reference level i.e. {0 0} within the dummies
# # b0 : average salary among Prof (Reference): (Intercept) 126772
# # b0 + b1 : average salary among AssocProf : (126772) + (-32895) 
# # b0 + b2 : average salary among AsstProf  : (126772) + (-45996) 
# # b1 : average difference in salary of AssocProf & Prof (Reference): (rankAssocProf) -32895
# # b2 : average difference in salary of AsstProf & Prof (Reference): (rankAssocProf) -45996
#
# #The p-value is 0 (significant), suggesting that there is a statistical evidence 
# #of a difference in average salary between the ranks

# #The fact that the coefficient for rankAssocProf & rankAsstProf in the regression output are 
# #negative indicates that lower ranks are associated with lower salary (relative to Prof).
```

### Complete Model {.unlisted .unnumbered}

```{r 'B25-AllX'}
# #y = b0 + b1 * x : Y (Salaries), X (Rank) with 3 levels
#
# #Change Factor Levels | Reference: Rank = Professor, Sex = Male, Discipline = A
bb <- as_tibble(Salaries) %>% 
  mutate(across(sex, factor, levels = c("Male", "Female"))) %>% 
  mutate(across(rank, factor, levels = c("Prof", "AssocProf", "AsstProf")))
#
# #contrasts() lists the dummy variables that would be created for k levels i.e. k-1 dummy 
contrasts(bb$rank)
contrasts(bb$sex)
contrasts(bb$discipline)
#
mod_bb <- lm(salary ~ ., data = bb)
if(TRUE) f_pNum(summary(mod_sal_r)$coefficients) %>% as_tibble(rownames = "DummyParVsRef") %>% 
  rename(pVal = "Pr(>|t|)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Anova Table of Base R
if(TRUE) anova(mod_bb) %>% as_tibble(rownames = "Predictors") %>% 
  rename(pVal = "Pr(>F)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Anova Table of Car Package which automatically takes care of unbalanced designs
if(TRUE) Anova(mod_bb) %>% as_tibble(rownames = "Predictors") %>% 
  rename(pVal = "Pr(>F)") %>% 
  mutate(pVal = ifelse(pVal < 0.001, 0, pVal), isSig = ifelse(pVal < 0.05, TRUE, FALSE))
#
# #Taking other variables into account, it can be seen that the categorical variable sex 
# #is no longer significantly associated with the variation in salary between individuals. 
# #Significant variables are rank and discipline.
```

### anova() vs. Anova() {.unlisted .unnumbered}

```{r 'B25-ANOVA'}
# #Anova Table of Base R (Type I : each variable is added in sequential order)
anova(mod_bb) %>% as_tibble(rownames = "Predictors")
#
# #Anova Table of Car Package which automatically takes care of unbalanced designs (Type II)
# #Type II tests each variable after all the others
# #There is a Type III also. However, its usage is highly controversial 
Anova(mod_bb, type = 2) %>% as_tibble(rownames = "Predictors")
```



## Validation {.unlisted .unnumbered .tabset .tabset-fade}

```{r 'B25-Cleanup', include=FALSE, cache=FALSE}
f_rmExist(aa, bb, ii, jj, kk, ll, dum_bb, m_Salaries, mod_bb, mod_sal_f, mod_sal_m, mod_sal_r, 
          r_Salaries, res_bb, Salaries, test_bb, xxB25CarDekho)
```

```{r 'B25-Validation', include=FALSE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), k_start)
```

****
